{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"0a_Workspace_setup.ipynb\"\n",
    "%run \"0b_Create_poi_files.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_id_sel = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful grouping functions for HRUs grouping--adopted from pyPRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_stream_network(dag_ds, uscutoff_seg, dsmost_seg):\n",
    "    \"\"\"Extract subset of stream network\n",
    "\n",
    "    :param dag_ds: Directed, acyclic graph of downstream stream network\n",
    "    :param uscutoff_seg: List of upstream cutoff segments\n",
    "    :param dsmost_seg: List of outlet segments to start extraction from\n",
    "\n",
    "    :returns: Stream network of extracted segments\n",
    "    \"\"\"\n",
    "\n",
    "    # taken from Bandit bandit_helpers.py\n",
    "\n",
    "    # Create the upstream graph\n",
    "    dag_us = dag_ds.reverse()\n",
    "\n",
    "    # Trim the u/s graph to remove segments above the u/s cutoff segments\n",
    "    try:\n",
    "        for xx in uscutoff_seg:\n",
    "            try:\n",
    "                dag_us.remove_nodes_from(nx.dfs_predecessors(dag_us, xx))\n",
    "\n",
    "                # Also remove the cutoff segment itself\n",
    "                dag_us.remove_node(xx)\n",
    "            except KeyError:\n",
    "                print(f\"WARNING: nhm_segment {xx} does not exist in stream network\")\n",
    "    except TypeError:\n",
    "        print(\n",
    "            \"\\nSelected cutoffs should at least be an empty list instead of NoneType.\"\n",
    "        )\n",
    "\n",
    "    # =======================================\n",
    "    # Given a d/s segment (dsmost_seg) create a subset of u/s segments\n",
    "\n",
    "    # Get all unique segments u/s of the starting segment\n",
    "    uniq_seg_us: Set[int] = set()\n",
    "    if dsmost_seg:\n",
    "        for xx in dsmost_seg:\n",
    "            try:\n",
    "                pred = nx.dfs_predecessors(dag_us, xx)\n",
    "                uniq_seg_us = uniq_seg_us.union(\n",
    "                    set(pred.keys()).union(set(pred.values()))\n",
    "                )\n",
    "            except KeyError:\n",
    "                print(f\"KeyError: Segment {xx} does not exist in stream network\")\n",
    "\n",
    "        # Get a subgraph in the dag_ds graph and return the edges\n",
    "        dag_ds_subset = dag_ds.subgraph(uniq_seg_us).copy()\n",
    "\n",
    "        node_outlets = [ee[0] for ee in dag_ds_subset.edges()]\n",
    "        true_outlets = set(dsmost_seg).difference(set(node_outlets))\n",
    "\n",
    "        # Add the downstream segments that exit the subgraph\n",
    "        for xx in true_outlets:\n",
    "            nhm_outlet = list(dag_ds.neighbors(xx))[0]\n",
    "            dag_ds_subset.add_node(\n",
    "                nhm_outlet, style=\"filled\", fontcolor=\"white\", fillcolor=\"grey\"\n",
    "            )\n",
    "            dag_ds_subset.add_edge(xx, nhm_outlet)\n",
    "            dag_ds_subset.nodes[xx][\"style\"] = \"filled\"\n",
    "            dag_ds_subset.nodes[xx][\"fontcolor\"] = \"white\"\n",
    "            dag_ds_subset.nodes[xx][\"fillcolor\"] = \"blue\"\n",
    "    else:\n",
    "        # No outlets specified so pull the full model\n",
    "        dag_ds_subset = dag_ds\n",
    "\n",
    "    return dag_ds_subset\n",
    "\n",
    "\n",
    "def hrus_by_seg(pdb, segs):\n",
    "    # segs: global segment IDs\n",
    "\n",
    "    if isinstance(segs, int):\n",
    "        segs = [segs]\n",
    "    elif isinstance(segs, KeysView):\n",
    "        segs = list(segs)\n",
    "\n",
    "    seg_hrus = {}\n",
    "    seg_to_hru = pdb.seg_to_hru\n",
    "\n",
    "    # Generate stream network for the model\n",
    "    dag_streamnet = pdb.stream_network()\n",
    "\n",
    "    for cseg in segs:\n",
    "        # Lookup segment for the current POI\n",
    "        dsmost_seg = [cseg]\n",
    "\n",
    "        # Get subset of stream network for given POI\n",
    "        dag_ds_subset = subset_stream_network(dag_streamnet, set(), dsmost_seg)\n",
    "\n",
    "        # Create list of segments in the subset\n",
    "        toseg_idx = list(set(xx[0] for xx in dag_ds_subset.edges))\n",
    "\n",
    "        # Build list of HRUs that contribute to the POI\n",
    "        final_hru_list = []\n",
    "\n",
    "        for xx in toseg_idx:\n",
    "            try:\n",
    "                for yy in seg_to_hru[xx]:\n",
    "                    final_hru_list.append(yy)\n",
    "            except KeyError:\n",
    "                # print(f'Segment {xx} has no HRUs connected to it') # comment this out and add pass to not print the KeyError\n",
    "                pass\n",
    "        final_hru_list.sort()\n",
    "\n",
    "        seg_hrus[cseg] = final_hru_list\n",
    "\n",
    "    return seg_hrus\n",
    "\n",
    "\n",
    "def hrus_by_poi(pdb, poi):\n",
    "    if isinstance(poi, str):\n",
    "        poi = [poi]\n",
    "    elif isinstance(poi, KeysView):\n",
    "        poi = list(poi)\n",
    "\n",
    "    poi_hrus = {}\n",
    "    nhm_seg = pdb.get(\"nhm_seg\").data\n",
    "    pois_dict = pdb.poi_to_seg\n",
    "    seg_to_hru = pdb.seg_to_hru\n",
    "\n",
    "    # Generate stream network for the model\n",
    "    dag_streamnet = pdb.stream_network()\n",
    "\n",
    "    for cpoi in poi:\n",
    "        # Lookup global segment id for the current POI\n",
    "        dsmost_seg = [nhm_seg[pois_dict[cpoi] - 1]]\n",
    "\n",
    "        # Get subset of stream network for given POI\n",
    "        dag_ds_subset = subset_stream_network(dag_streamnet, set(), dsmost_seg)\n",
    "\n",
    "        # Create list of segments in the subset\n",
    "        toseg_idx = list(set(xx[0] for xx in dag_ds_subset.edges))\n",
    "\n",
    "        # Build list of HRUs that contribute to the POI\n",
    "        final_hru_list = []\n",
    "\n",
    "        for xx in toseg_idx:\n",
    "            try:\n",
    "                for yy in seg_to_hru[xx]:\n",
    "                    final_hru_list.append(yy)\n",
    "            except KeyError:\n",
    "                # Not all segments have HRUs connected to them\n",
    "                # print(f'{cpoi}: Segment {xx} has no HRUs connected to it')\n",
    "                pass\n",
    "        final_hru_list.sort()\n",
    "        poi_hrus[cpoi] = final_hru_list\n",
    "\n",
    "    return poi_hrus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Model Output file and merge selected output with the geodatabase  \n",
    "##### Open up the model output, this is a NetCDF file of all varables selected for output in the \"Run_Model\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "WY_start = \"1979-10-01\"\n",
    "# plot_start_dt = datetime.strptime(WY_start, \"%Y-%m-%d\").date()\n",
    "\n",
    "\n",
    "WY_end = \"2021-09-30\"\n",
    "# plot_end_dt = datetime.strptime(WY_end, \"%Y-%m-%d\").date()\n",
    "\n",
    "with xr.open_dataset(out_dir / \"seg_outflow.nc\") as model_output:\n",
    "    output = model_output.sel(time=slice(WY_start, WY_end))\n",
    "    year_list = list(set(((output.time.dt.year).values).ravel().tolist()))\n",
    "\n",
    "    # output_var_start_date = output.time.values[0]\n",
    "    output_var_start_date = (pd.to_datetime(str(output.time.values[0]))).strftime(\n",
    "        \"%Y-%m-%d\"\n",
    "    )\n",
    "    plot_start_dt = datetime.strptime(output_var_start_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    output_var_end_date = (pd.to_datetime(str(output.time.values[-1]))).strftime(\n",
    "        \"%Y-%m-%d\"\n",
    "    )\n",
    "    plot_end_dt = datetime.strptime(output_var_end_date, \"%Y-%m-%d\").date()\n",
    "    del output\n",
    "\n",
    "output_var_list = set([vv.stem for vv in out_dir.glob(\"*.nc\")])\n",
    "# This vars dimensioned by nseg,in another notebook.\n",
    "output_var_list = list(\n",
    "    output_var_list - {\"seg_outflow\", \"model_custom_output\", \"hru_streamflow_out\"}\n",
    ")\n",
    "print(f\"{output_var_list=}\")\n",
    "\n",
    "# Note: Model output is in calendar years, so must remove first year from the list to show available WY's in the data\n",
    "year_list.remove(year_list[0])\n",
    "year_list = [str(x) for x in year_list]\n",
    "# output_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output variable units\n",
    "from ast import literal_eval\n",
    "\n",
    "for var in output_var_list:\n",
    "    # units = f'output.{var}.units'\n",
    "    ds = xr.open_dataset(out_dir / f\"{var}.nc\")\n",
    "    print(f\"{var}: {ds[var].units}\")\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a spatial output variable (by HRU) to process and a year to viewlist above dimensioned by \"nhru.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from ipywidgets import Text, HBox, VBox, Box\n",
    "from IPython.display import display\n",
    "\n",
    "##### Varibale selection widget\n",
    "output_var_sel = output_var_list[\n",
    "    1\n",
    "]  # Set a default value so that the notebook will run without selection\n",
    "\n",
    "style_date = {\"description_width\": \"initial\"}\n",
    "\n",
    "style_var = {\"description_width\": \"initial\"}\n",
    "\n",
    "v = widgets.Dropdown(\n",
    "    options=output_var_list,\n",
    "    value=output_var_list[1],\n",
    "    description=\"Output variable for map and plot:\",\n",
    "    layout=widgets.Layout(width=\"35%\"),\n",
    "    style=style_var,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change(change):\n",
    "    global output_var_sel, sel_flag\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        output_var_sel = v.value\n",
    "        # sel_flag = True\n",
    "\n",
    "\n",
    "v.observe(on_change)\n",
    "# display(v)\n",
    "\n",
    "##### Year selection widget\n",
    "list_of_years = year_list.copy()\n",
    "list_of_years.append(\n",
    "    \"mean_annual\"\n",
    ")  # Append the mean annual so that the default will not be a year\n",
    "sel_year = list_of_years[\n",
    "    -1\n",
    "]  # Set a default value so that the notebook will run without selection\n",
    "\n",
    "yr = widgets.Dropdown(\n",
    "    options=list_of_years,\n",
    "    value=list_of_years[-1],\n",
    "    description=\"Time step (year) for map:\",\n",
    "    layout=widgets.Layout(width=\"35%\"),\n",
    "    style=style_var,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change(change):\n",
    "    global sel_year  # Have to set the var as global so that it is carried outside of the fucntion to the notebook\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        sel_year = yr.value\n",
    "\n",
    "\n",
    "yr.observe(on_change)\n",
    "\n",
    "#####################################\n",
    "# Add widgets for start and end date, and for picking the gage here.\n",
    "\n",
    "global plot_start_dt, plot_end_dt, output_var_end_date, output_var_start_date, plot_end_date, plot_start_date, poi_id_sel\n",
    "plot_end_date = output_var_end_date\n",
    "plot_start_date = output_var_start_date\n",
    "\n",
    "st_date = widgets.DatePicker(\n",
    "    description=\"Start date for plot:\",\n",
    "    disabled=False,\n",
    "    value=plot_start_dt,\n",
    "    min=plot_start_dt,\n",
    "    max=plot_end_dt,\n",
    "    layout=widgets.Layout(width=\"25%\"),\n",
    "    style=style_date,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change_st_date(change):\n",
    "    global plot_start_date  # , sel_flag\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        plot_start_date = st_date.value.strftime(\"%Y-%m-%d\")\n",
    "        # sel_flag = True\n",
    "\n",
    "\n",
    "st_date.observe(on_change_st_date)\n",
    "\n",
    "#### End Date\n",
    "end_date = widgets.DatePicker(\n",
    "    description=\"End date for plot:\",\n",
    "    disabled=False,\n",
    "    value=plot_end_dt,\n",
    "    min=plot_start_dt,\n",
    "    max=plot_end_dt,\n",
    "    layout=widgets.Layout(width=\"25%\"),\n",
    "    style=style_date,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change_end_date(change):\n",
    "    global plot_end_date  # , sel_flag\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        plot_end_date = end_date.value.strftime(\"%Y-%m-%d\")\n",
    "        # sel_flag = True\n",
    "\n",
    "\n",
    "end_date.observe(on_change_end_date)\n",
    "\n",
    "#################################################\n",
    "v2 = widgets.Combobox(\n",
    "    # value=poi_df.poi_id.tolist()[0],\n",
    "    placeholder=\"(optional) Enter Gage ID here\",\n",
    "    options=poi_df.poi_id.tolist(),\n",
    "    description=\"Plot Gage:\",\n",
    "    ensure_option=True,\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width=\"35%\"),\n",
    "    style=style_var,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change2(change):\n",
    "    global poi_id_sel, fig\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        poi_id_sel = v2.value\n",
    "\n",
    "\n",
    "v2.observe(on_change2)\n",
    "\n",
    "display(VBox([v, yr, st_date, end_date, v2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click here and select \"Run Selected Cell and All Below\" from the \"Run\" menu in the toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JLM TODO\n",
    "if poi_id_sel is None:\n",
    "    poi_id_sel = poi_df.poi_id.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.print(f\"{output_var_sel}, {sel_year}, {poi_id_sel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get data for map and first plot\n",
    "# with xr.open_dataset(custom_output_file) as model_output:\n",
    "#     output_var = model_output.sel(time=slice(WY_start, WY_end))\n",
    "#     # output_var_daily = getattr(output_var, output_var_sel)\n",
    "#     output_var_daily = output_var[output_var_sel]\n",
    "#     output_var_annual = (\n",
    "#         getattr(output_var, output_var_sel).resample(time=\"A-SEP\").sum()\n",
    "#     )  # Water year\n",
    "#     output_var_monthly = (\n",
    "#         getattr(output_var, output_var_sel).resample(time=\"m\").sum()\n",
    "#     )  # monthly\n",
    "\n",
    "# ### actet_daily = modelobsdat.hru_actet.sel(time=slice(aet_start, aet_end))#Slice example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JLM TODO: why are these sums? below means are calculated...\n",
    "with xr.load_dataarray(out_dir / f\"{output_var_sel}.nc\") as da:\n",
    "    # these machinations are to keep downstream things as they were before some refactoring\n",
    "    da = da.to_dataset().rename_dims({\"nhm_id\": \"nhru\"})[da.name]\n",
    "    output_var_daily = da.sel(time=slice(WY_start, WY_end))\n",
    "    output_var_monthly = output_var_daily.resample(time=\"m\").sum()\n",
    "    # Water year annual\n",
    "    output_var_annual = output_var_daily.resample(time=\"A-SEP\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr.testing.assert_equal(output_var_daily, output_var_daily2)\n",
    "# xr.testing.assert_equal(output_var_monthly, output_var_monthly2)\n",
    "# xr.testing.assert_equal(output_var_annual, output_var_annual2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change data_array from .nc to a DataFrame\n",
    "#### This dataframe will be used to 1) output a .csv, 2) map data to the GIS, and 3) plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_output_var_annual = output_var_annual.copy()\n",
    "df_output_var_annual = ds_output_var_annual.to_dataframe(dim_order=[\"time\", \"nhru\"])\n",
    "df_output_var_annual.reset_index(inplace=True, drop=False)\n",
    "df_output_var_annual.set_index(\n",
    "    \"nhm_id\", inplace=True, drop=True\n",
    ")  # resets the index to that new value and type\n",
    "\n",
    "df_output_var_annual[\"year\"] = pd.DatetimeIndex(df_output_var_annual[\"time\"]).year\n",
    "df_output_var_annual.year = df_output_var_annual.year.astype(str)\n",
    "df_output_var_annual.rename(\n",
    "    columns={output_var_sel: \"output_var\"}, inplace=True\n",
    ")  # Rename the column to a general heading for later code\n",
    "\n",
    "df_output_var_annual.drop(columns=[\"time\", \"nhru\"], inplace=True)\n",
    "\n",
    "# year_list = list(df_output_var_annual['year'].unique())\n",
    "# year_list\n",
    "year_list_str = [str(x) for x in year_list]\n",
    "\n",
    "# df_output_var_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export a database of selected output var data as a table (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(\n",
    "    df_output_var_annual,\n",
    "    values=\"output_var\",\n",
    "    index=[\"nhm_id\"],\n",
    "    columns=[\"year\"],\n",
    ").round(2)\n",
    "table.reset_index(inplace=True, drop=False)\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select only hru's in a domain: Walla Walla subabasin model\n",
    "# subbasin_hrus = [99000,99003,98963,99049,98957,99050,98947,98951,98874,98875,98753,98764,98974,99147,98960,98983,99899,\n",
    "#                  99900,98802,98804,98789,98792,98813,98814,98803,98811,98801,98806,98939,98962,98936,98940,98937,98941,\n",
    "#                  98903,98904,98861,98884,99581,99618,99030,99141,99043,99065,98930,98935,99042,99081,99920,99921,99182,\n",
    "#                  99204,99183,99202,99162,99167,99125,99160,99113,99114,99075,99076,99132,99159,99131,99136,99580,99617,\n",
    "#                  99145,99173,99170,99219,99574,99614,98905,98907,98901,98915,98876,98877,98828,98933,98934,99566,99615,\n",
    "#                  99237,99261,99578,99616,99056,99099]\n",
    "# table_sub = table.loc[table['nhm_id'].isin(subbasin_hrus),:]\n",
    "# table_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = f\"{shapefile_dir}/{output_var_sel}_annual_{da.units}.csv\"  # Writes gpd GeoDataFrame our t as a shapefile for fun\n",
    "table.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge in the geometry from the geodatabase with the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_output_var_annual = hru_gdf.merge(table, on=\"nhm_id\")\n",
    "gdf_output_var_annual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_output_var_annual = hru_gdf.merge(table, on=\"nhm_id\")\n",
    "gdf_output_var_annual.drop(\n",
    "    columns=[\"hru_lat\", \"hru_lon\", \"hru_segment_nhm\", \"model_idx\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_output_var_annual\n",
    "# isinstance(gdf_output_var_annual, gpd.GeoDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the mean annual value for the model simulation period, year_list\n",
    "for nhm_id in gdf_output_var_annual:\n",
    "    gdf_output_var_annual[\"mean_annual\"] = gdf_output_var_annual[year_list].mean(axis=1)\n",
    "# gdf_output_var_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_output_var_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an interactive map with model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the minimum and maximum values for annual recharge for the legend value bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_min = gdf_output_var_annual[year_list].min().min()\n",
    "value_max = gdf_output_var_annual[year_list].max().max()\n",
    "\n",
    "# value_mean = gdf_output_var_annual[[sel_years]].mean(axis=1)\n",
    "# value_med = gdf_output_var_annual[[sel_years]].median(axis=1)\n",
    "\n",
    "print(f\"The minimum and maximum annual values are: {value_min}, {value_max}.\")\n",
    "print(\n",
    "    \"This will be used to set a values in the legend bar when mapping the annual data.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the gdf projection for mapping\n",
    "hru_gdf_map = hru_gdf.to_crs(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pfile lat, lon derived for starting point of folium plot windows. Zoom also set here.\n",
    "lat = hru_gdf_map[\"hru_lat\"].mean()\n",
    "lon = hru_gdf_map[\"hru_lon\"].mean() - 1\n",
    "zoom = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basemaps for map\n",
    "USGStopo_layer = folium.TileLayer(\n",
    "    tiles=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSTopo/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"USGS_topo\",\n",
    "    zoom_start=zoom,\n",
    "    name=\"USGSTopo\",\n",
    ")\n",
    "USGSHydroCached_layer = folium.TileLayer(\n",
    "    tiles=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSHydroCached/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"USGSHydroCached\",\n",
    "    zoom_start=zoom,\n",
    "    name=\"USGSHydroCached\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inset map object\n",
    "minimap = plugins.MiniMap(\n",
    "    tile_layer=\"OpenStreetMap\",\n",
    "    # attr = 'USGS_topo',\n",
    "    position=\"topleft\",\n",
    "    # zoom_level_offset=- 4,\n",
    "    height=200,\n",
    "    width=200,\n",
    "    collapsed_height=25,\n",
    "    collapsed_width=25,\n",
    "    zoom_level_fixed=5,\n",
    "    toggle_display=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set style functions\n",
    "style_function_hru_map = lambda x: {\n",
    "    \"opacity\": 1,\n",
    "    \"fillColor\": \"#00000000\",  #'goldenrod',\n",
    "    \"color\": \"tan\",\n",
    "    \"weight\": 1.5,\n",
    "}\n",
    "highlight_function_hru_map = lambda x: {\n",
    "    \"opacity\": 0.5,\n",
    "    \"color\": \"gray\",\n",
    "    \"fillColor\": \"gray\",\n",
    "    \"weight\": 3,\n",
    "}\n",
    "style_function_seg_map = lambda x: {\"opacity\": 1, \"color\": \"#217de7\", \"weight\": 2}\n",
    "highlight_function_seg_map = lambda x: {\"opacity\": 1, \"color\": \"white\", \"weight\": 4}\n",
    "transparent = lambda x: {\n",
    "    \"fillColor\": \"#00000000\",\n",
    "    \"color\": \"#00000000\",\n",
    "    \"weight\": 4,\n",
    "}\n",
    "cp_style_function = lambda feature: {\n",
    "    \"fillColor\": linear(var_sel_color_dict[feature[\"id\"]]),\n",
    "    \"color\": \"tan\",\n",
    "    \"weight\": 1,\n",
    "    # \"dashArray\": \"5, 5\",\n",
    "    \"fillOpacity\": 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output bins for color dictionary\n",
    "hru_gdf_copy = gdf_output_var_annual.copy().reset_index().to_crs(crs)\n",
    "hru_gdf_copy[\"nhm_id\"] = hru_gdf_copy[\"nhm_id\"].astype(str)\n",
    "hru_gdf_copy.set_index(\"nhm_id\", inplace=True, drop=False)\n",
    "\n",
    "var_subset_df = gdf_output_var_annual.loc[:, [\"nhm_id\", str(sel_year)]]\n",
    "var_subset_df[\"nhm_id\"] = var_subset_df[\"nhm_id\"].astype(str)\n",
    "var_subset_df.rename(columns={f\"{sel_year}\": \"var_value\"}, inplace=True)\n",
    "var_subset_df[\"var_value\"] = np.round(var_subset_df[\"var_value\"], 4)\n",
    "var_subset_df.set_index(\"nhm_id\", inplace=True, drop=False)\n",
    "\n",
    "value_min = np.round(var_subset_df[\"var_value\"].min(), 8)\n",
    "value_max = np.round(var_subset_df[\"var_value\"].max(), 8)\n",
    "\n",
    "\n",
    "var_sel_color_dict = pd.Series(\n",
    "    var_subset_df.var_value.values, index=var_subset_df.nhm_id\n",
    ").to_dict()\n",
    "\n",
    "# Making par_bins\n",
    "sdv = var_subset_df[\"var_value\"].std()\n",
    "mean = var_subset_df[\"var_value\"].mean()\n",
    "\n",
    "var_bins = [\n",
    "    value_min,\n",
    "    np.round(value_min + (0.25 * (mean - value_min)), 5),\n",
    "    np.round(value_min + (0.50 * (mean - value_min)), 5),\n",
    "    np.round(value_min + (0.75 * (mean - value_min)), 5),\n",
    "    np.round(mean, 3),\n",
    "    np.round(value_max - (0.75 * (value_max - mean)), 5),\n",
    "    np.round(value_max - (0.50 * (value_max - mean)), 5),\n",
    "    np.round(value_max - (0.25 * (value_max - mean)), 5),\n",
    "    value_max,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom to Gage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zoom to gage, just uncomment the lines below\n",
    "\n",
    "# poi_lookup = poi_id_sel\n",
    "# lat = poi_df.loc[poi_df.poi_id==poi_lookup, 'latitude'].values[0]\n",
    "# lon = poi_df.loc[poi_df.poi_id==poi_lookup, 'longitude'].values[0]\n",
    "# zoom = 12\n",
    "\n",
    "# if poi_id_sel:\n",
    "#     poi_lookup = poi_id_sel\n",
    "#     lat = poi_df.loc[poi_df.poi_id==poi_lookup, 'latitude'].values[0]\n",
    "#     lon = poi_df.loc[poi_df.poi_id==poi_lookup, 'longitude'].values[0]\n",
    "#     zoom = 12\n",
    "# else:\n",
    "#     lat = hru_gdf_map['hru_lat'].mean()\n",
    "#     lon =  hru_gdf_map['hru_lon'].mean()-1\n",
    "#     zoom = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Map\n",
    "if poi_id_sel:\n",
    "    poi_lookup = poi_id_sel\n",
    "    lat = poi_df.loc[poi_df.poi_id == poi_lookup, \"latitude\"].values[0]\n",
    "    lon = poi_df.loc[poi_df.poi_id == poi_lookup, \"longitude\"].values[0]\n",
    "    zoom = 12\n",
    "    # poi_id_sel= None\n",
    "else:\n",
    "    lat = hru_gdf_map[\"hru_lat\"].mean()\n",
    "    lon = hru_gdf_map[\"hru_lon\"].mean() - 1\n",
    "    zoom = 7\n",
    "\n",
    "m3 = folium.Map(\n",
    "    location=[lat, lon],\n",
    "    # width=1000, height=600,\n",
    "    tiles=USGSHydroCached_layer,\n",
    "    zoom_start=zoom,\n",
    "    control_scale=True,\n",
    ")\n",
    "folium.TileLayer(\n",
    "    tiles=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSTopo/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"USGS_Topo\",\n",
    "    zoom_start=zoom,\n",
    "    name=\"USGS Topography\",\n",
    "    show=False,\n",
    ").add_to(m3)\n",
    "\n",
    "#########################################################################################\n",
    "hru_gdf_copy = gdf_output_var_annual.copy().reset_index().to_crs(crs)\n",
    "hru_gdf_copy[\"nhm_id\"] = hru_gdf_copy[\"nhm_id\"].astype(str)\n",
    "hru_gdf_copy.set_index(\"nhm_id\", inplace=True, drop=False)\n",
    "\n",
    "var_subset_df = gdf_output_var_annual.loc[:, [\"nhm_id\", str(sel_year)]]\n",
    "var_subset_df[\"nhm_id\"] = var_subset_df[\"nhm_id\"].astype(str)\n",
    "var_subset_df.rename(columns={f\"{sel_year}\": \"var_value\"}, inplace=True)\n",
    "var_subset_df[\"var_value\"] = np.round(var_subset_df[\"var_value\"], 4)\n",
    "var_subset_df.set_index(\"nhm_id\", inplace=True, drop=False)\n",
    "\n",
    "value_min = np.round(var_subset_df[\"var_value\"].min(), 8)\n",
    "value_max = np.round(var_subset_df[\"var_value\"].max(), 8)\n",
    "\n",
    "\n",
    "var_sel_color_dict = pd.Series(\n",
    "    var_subset_df.var_value.values, index=var_subset_df.nhm_id\n",
    ").to_dict()\n",
    "\n",
    "# Making par_bins\n",
    "sdv = var_subset_df[\"var_value\"].std()\n",
    "mean = var_subset_df[\"var_value\"].mean()\n",
    "\n",
    "var_bins = [\n",
    "    value_min,\n",
    "    np.round(value_min + (0.25 * (mean - value_min)), 5),\n",
    "    np.round(value_min + (0.50 * (mean - value_min)), 5),\n",
    "    np.round(value_min + (0.75 * (mean - value_min)), 5),\n",
    "    np.round(mean, 3),\n",
    "    np.round(value_max - (0.75 * (value_max - mean)), 5),\n",
    "    np.round(value_max - (0.50 * (value_max - mean)), 5),\n",
    "    np.round(value_max - (0.25 * (value_max - mean)), 5),\n",
    "    value_max,\n",
    "]\n",
    "\n",
    "#################################################\n",
    "fig, ax = plt.subplots(figsize=(18, 0.5))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "cmap = mplib.colors.ListedColormap(\n",
    "    [\n",
    "        \"#8B0000\",\n",
    "        \"#AC4800\",\n",
    "        \"#CD9100\",\n",
    "        \"#EEDA00\",\n",
    "        \"#DADA13\",\n",
    "        \"#91913B\",\n",
    "        \"#484863\",\n",
    "        \"#00008B\",\n",
    "    ]\n",
    ")\n",
    "cmap.set_over(\"0.25\")\n",
    "cmap.set_under(\"0.75\")\n",
    "\n",
    "bounds = var_bins\n",
    "norm = mplib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "cb2 = mplib.colorbar.ColorbarBase(\n",
    "    ax,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    boundaries=[0] + bounds + [13],\n",
    "    extend=None,\n",
    "    ticks=bounds,\n",
    "    spacing=\"uniform\",\n",
    "    orientation=\"horizontal\",\n",
    "    alpha=0.45,\n",
    ")\n",
    "cb2.set_label(\n",
    "    f\"Discrete {output_var_sel} intervals\"\n",
    ")  # , {pdb.get(output_var_sel).units}')\n",
    "\n",
    "fig.set_facecolor(\"lightgray\")\n",
    "fig.show()\n",
    "\n",
    "#######################################################\n",
    "\n",
    "linear = cm.StepColormap(\n",
    "    colors=[\n",
    "        \"#8B0000\",\n",
    "        \"#AC4800\",\n",
    "        \"#CD9100\",\n",
    "        \"#EEDA00\",\n",
    "        \"#DADA13\",\n",
    "        \"#91913B\",\n",
    "        \"#484863\",\n",
    "        \"#00008B\",\n",
    "    ],\n",
    "    index=var_bins,\n",
    "    vmin=0.00,\n",
    "    vmax=0.05,\n",
    "    caption=\"Total Standard deviation at the point[mm]\",\n",
    "    # tick_labels= ('0.01', '0.02', '0.03', '0.04')\n",
    ")\n",
    "popup_hru = folium.GeoJsonPopup(\n",
    "    fields=[\"nhm_id\", str(sel_year)],\n",
    "    aliases=[\"HRU\", f\"{output_var_sel} for {sel_year}\"],\n",
    "    labels=True,\n",
    "    localize=True,\n",
    "    style=(\n",
    "        \"font-size: 16px;\"\n",
    "    ),  # Note that this tooltip style sets the style for all tool_tips.\n",
    "    # background-color: #F0EFEF;border: 2px solid black;font-family: arial; padding: 10px; background-color: #F0EFEF;\n",
    ")\n",
    "\n",
    "hru_map = folium.GeoJson(\n",
    "    hru_gdf_copy,\n",
    "    style_function=cp_style_function,  # style_function_hru_map,\n",
    "    highlight_function=highlight_function_hru_map,\n",
    "    name=\"NHM HRUs\",\n",
    "    popup=popup_hru,\n",
    "    z_index_offset=40002,\n",
    ").add_to(m3)\n",
    "\n",
    "# tooltip_hru=folium.GeoJsonPopup(fields= [\"nhm_id\",str(sel_year)],\n",
    "#                                   aliases=[\"HRU\", \"var value\"],\n",
    "#                                   labels=True)\n",
    "\n",
    "# tooltip_hru=folium.GeoJsonTooltip(fields= [\"nhm_id\",str(sel_year)],\n",
    "#                                   aliases=[\"HRU\", f\"{output_var_sel} for {sel_year}\"],\n",
    "#                                   labels=True,\n",
    "#                                   localize=True,\n",
    "#                                   style=(\"background-color: #F0EFEF;border: 2px solid black;font-family: arial; font-size: 16px; padding: 10px;\"),\n",
    "#                                      )\n",
    "\n",
    "\n",
    "# Add tool tip to map\n",
    "# hru_map.add_child(tooltip_hru)\n",
    "\n",
    "\n",
    "# Create and add segments map\n",
    "popup_seg = folium.GeoJsonPopup(\n",
    "    fields=[\"nhm_seg\", \"tosegment_nhm\"],\n",
    "    aliases=[\"segment\", \"flows to segment\"],\n",
    "    labels=True,\n",
    "    localize=False,\n",
    ")\n",
    "seg_map = folium.GeoJson(\n",
    "    seg_gdf,\n",
    "    style_function=style_function_seg_map,\n",
    "    highlight_function=highlight_function_seg_map,  # lambda feature: {\"fillcolor\": \"white\", \"color\": \"white\"},\n",
    "    name=\"NHM Segments\",\n",
    "    control=True,\n",
    "    popup=popup_seg,\n",
    "    z_index_offset=40003,\n",
    ").add_to(m3)\n",
    "\n",
    "# tooltip_seg=folium.GeoJsonTooltip(fields= [\"nhm_seg\"],\n",
    "#                                   aliases=[\"Segment\"],\n",
    "#                                   labels=True)\n",
    "# seg_map.add_child(tooltip_seg)\n",
    "\n",
    "\n",
    "# add POI markers\n",
    "\n",
    "marker_cluster = MarkerCluster(\n",
    "    name=\"All the POIs\",\n",
    "    overlay=True,\n",
    "    control=True,\n",
    "    icon_create_function=None,\n",
    "    disableClusteringAtZoom=9,\n",
    "    z_index_offset=5000,\n",
    ")\n",
    "\n",
    "marker_cluster_label_poi = MarkerCluster(\n",
    "    name=\"All the POI labels\",\n",
    "    overlay=True,\n",
    "    control=True,\n",
    "    show=False,  # False will not draw the child upon opening the map, but have it to draw in the Layer control.\n",
    "    icon_create_function=None,\n",
    "    disableClusteringAtZoom=9,\n",
    "    z_index_offset=4004,\n",
    ")\n",
    "\n",
    "marker_cluster_label_hru = MarkerCluster(\n",
    "    name=\"All HRU labels\",\n",
    "    overlay=True,\n",
    "    control=True,\n",
    "    show=False,  # False will not draw the child upon opening the map, but have it to draw in the Layer control.\n",
    "    icon_create_function=None,\n",
    "    disableClusteringAtZoom=9,\n",
    "    z_index_offset=4005,\n",
    ")\n",
    "\n",
    "\n",
    "m3.add_child(minimap)\n",
    "\n",
    "# Create Popup for the byHRU_map\n",
    "# popup_byHRU=folium.GeoJsonPopup(fields= ['nhm_id_label', str(sel_year)],\n",
    "#                                 aliases=['HRU' , output_var_sel],\n",
    "#                                 labels=True, localize = True)\n",
    "\n",
    "label_coord_x = 20\n",
    "label_coor_y = 10\n",
    "\n",
    "for idx, row in poi_df.iterrows():\n",
    "    poi_id = row[\"poi_id\"]\n",
    "    marker = folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        name=row[\"poi_id\"],\n",
    "        popup=folium.Popup(\n",
    "            f'<font size=\"3px\">{row[\"poi_id\"]}<br>{row[\"poi_name\"]}</font>',\n",
    "            max_width=280,\n",
    "            max_height=2000,\n",
    "        ),\n",
    "        radius=4,\n",
    "        weight=2,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        fill_color=\"Yellow\",\n",
    "        fill_opacity=1.0,\n",
    "        draggable=True,\n",
    "        z_index_offset=4006,\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    # marker_cluster.add_child(marker)\n",
    "    text = f'{row[\"poi_id\"]}'\n",
    "    label_lat = row[\"latitude\"] - 0.01\n",
    "    label_lon = row[\"longitude\"]\n",
    "\n",
    "    marker_label = folium.map.Marker(\n",
    "        [label_lat, label_lon],\n",
    "        z_index_offset=4007,\n",
    "        icon=DivIcon(\n",
    "            icon_size=(150, 36),\n",
    "            icon_anchor=(0, 0),\n",
    "            html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>' % text,\n",
    "        ),\n",
    "    ).add_to(marker_cluster_label_poi)\n",
    "\n",
    "\n",
    "hru_gdf_label = hru_gdf.copy()\n",
    "hru_gdf_label.reset_index(inplace=True, drop=False)\n",
    "\n",
    "for idx, row in hru_gdf_label.iterrows():\n",
    "    text = f'{row[\"nhm_id\"]}'\n",
    "    label_lat = row[\"hru_lat\"]\n",
    "    label_lon = row[\"hru_lon\"]\n",
    "    marker_label = folium.map.Marker(\n",
    "        [label_lat, label_lon],\n",
    "        z_index_offset=4008,\n",
    "        icon=DivIcon(\n",
    "            icon_size=(150, 36),\n",
    "            icon_anchor=(0, 0),\n",
    "            html='<div style=\"font-family: verdona; font-size: 10pt; font-weight: bold; color: black; text-shadow: 1px 1px 2px white;\">%s</div>'\n",
    "            % text,\n",
    "        ),\n",
    "    ).add_to(marker_cluster_label_hru)\n",
    "\n",
    "marker_cluster.add_to(m3)\n",
    "marker_cluster_label_poi.add_to(m3)\n",
    "marker_cluster_label_hru.add_to(m3)\n",
    "\n",
    "plugins.Fullscreen(position=\"topleft\").add_to(m3)\n",
    "\n",
    "\n",
    "folium.LayerControl(collapsed=True, position=\"bottomright\", autoZIndex=True).add_to(m3)\n",
    "\n",
    "con.print(f\"\")\n",
    "con.print(f\"\")\n",
    "con.print(f\"\")\n",
    "con.print(f\"NHM simulated {sel_year} {output_var_sel}\", style=\"u bold black\")\n",
    "\n",
    "m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare HRU outputs by catchment for selected year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make groups of HRUs for POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group HRUs for each gage--these are all HRUs that contribute to each gage.\n",
    "\n",
    "hru_gdf.reset_index(inplace=True)\n",
    "\n",
    "# Create poi list from the POI dataframe\n",
    "poi_list = poi[\"poi_gage_id\"].values.tolist()\n",
    "\n",
    "# Make a dictionary of pois and the list of HRUs in the contributing area for each poi\n",
    "hru_poi_dict = hrus_by_poi(pdb, poi_list)  # Helper function from pyPRMS\n",
    "\n",
    "# Sort the dictionary: this is important for the reverse dictionary (next step)\n",
    "# to accurately give a poi_group to hrus that contribute to a downstream-gage\n",
    "sorted_items = sorted(\n",
    "    hru_poi_dict.items(), key=lambda item: -len(item[1])\n",
    ")  # the - reverses the sorting order\n",
    "hru_poi_dict = dict(sorted_items[:])\n",
    "\n",
    "reversed_hru_poi_dict = {val: key for key in hru_poi_dict for val in hru_poi_dict[key]}\n",
    "\n",
    "# assigns poi_group value to all hrus#Keep for later application\n",
    "hru_gdf[\"poi_group\"] = hru_gdf[\"nhm_id\"].map(reversed_hru_poi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of ANNUAL recharge values for each HRU\n",
    "hru_area_df = hru_gdf[[\"hru_area\", \"nhm_id\"]].set_index(\n",
    "    \"nhm_id\", drop=True\n",
    ")  # Consider a dictionary from the par file and using .map() instead of merge\n",
    "\n",
    "ds_output_var_annual_basin = output_var_annual.copy().sel(\n",
    "    time=slice(plot_start_date, plot_end_date)\n",
    ")\n",
    "\n",
    "df_output_var_annual_basin = ds_output_var_annual_basin.to_dataframe(\n",
    "    dim_order=[\"time\", \"nhru\"]\n",
    ")\n",
    "df_output_var_annual_basin.reset_index(inplace=True, drop=False)\n",
    "\n",
    "df_output_var_annual_basin = df_output_var_annual_basin.merge(\n",
    "    hru_area_df, how=\"left\", right_index=True, left_on=\"nhm_id\"\n",
    ")\n",
    "\n",
    "# # add the HRU area to the dataframe\n",
    "# for idx, row in df_output_var_annual_basin.iterrows():\n",
    "#     df_output_var_annual_basin.loc[idx, 'hru_area'] = hru_gdf.loc[hru_gdf.nhm_id == row.nhm_id, 'hru_area'].item()\n",
    "\n",
    "# Add recharge volume to the dataframe\n",
    "df_output_var_annual_basin[\"vol\"] = (\n",
    "    df_output_var_annual_basin[output_var_sel] * df_output_var_annual_basin[\"hru_area\"]\n",
    ")\n",
    "\n",
    "# Drop unneeded columns\n",
    "df_output_var_annual_basin.drop(columns=[\"nhru\"], inplace=True)\n",
    "# df_output_var_annual_basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of MONTHLY recharge values for each HRU\n",
    "ds_output_var_monthly_basin = output_var_monthly.copy().sel(\n",
    "    time=slice(plot_start_date, plot_end_date)\n",
    ")\n",
    "\n",
    "df_output_var_monthly_basin = ds_output_var_monthly_basin.to_dataframe(\n",
    "    dim_order=[\"time\", \"nhru\"]\n",
    ")\n",
    "df_output_var_monthly_basin.reset_index(inplace=True, drop=False)\n",
    "\n",
    "# add the HRU area to the dataframe\n",
    "df_output_var_monthly_basin = df_output_var_monthly_basin.merge(\n",
    "    hru_area_df, how=\"left\", right_index=True, left_on=\"nhm_id\"\n",
    ")\n",
    "\n",
    "# Add recharge volume to the dataframe\n",
    "df_output_var_monthly_basin[\"vol\"] = (\n",
    "    df_output_var_monthly_basin[output_var_sel]\n",
    "    * df_output_var_monthly_basin[\"hru_area\"]\n",
    ")\n",
    "\n",
    "# Drop unneeded columns\n",
    "df_output_var_monthly_basin.drop(columns=[\"nhru\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of Daily recharge values for each HRU\n",
    "ds_output_var_daily_basin = output_var_daily.copy().sel(\n",
    "    time=slice(plot_start_date, plot_end_date)\n",
    ")\n",
    "\n",
    "df_output_var_daily_basin = ds_output_var_daily_basin.to_dataframe(\n",
    "    dim_order=[\"time\", \"nhru\"]\n",
    ")\n",
    "df_output_var_daily_basin.reset_index(inplace=True, drop=False)\n",
    "\n",
    "# add the HRU area to the dataframe\n",
    "df_output_var_daily_basin = df_output_var_daily_basin.merge(\n",
    "    hru_area_df, how=\"left\", right_index=True, left_on=\"nhm_id\"\n",
    ")\n",
    "\n",
    "# Add recharge volume to the dataframe\n",
    "df_output_var_daily_basin[\"vol\"] = (\n",
    "    df_output_var_daily_basin[output_var_sel] * df_output_var_daily_basin[\"hru_area\"]\n",
    ")\n",
    "\n",
    "# Drop unneeded columns\n",
    "df_output_var_daily_basin.drop(columns=[\"nhru\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paste the poi_id in the field below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = widgets.Combobox(\n",
    "    value=poi_id_sel,\n",
    "    placeholder=\"Select Gage ID here\",\n",
    "    options=poi_df.poi_id.tolist(),\n",
    "    description=\"Plot Gage:\",\n",
    "    ensure_option=True,\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change3(change):\n",
    "    global poi_id_sel, fig\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        poi_id_sel = v3.value\n",
    "\n",
    "\n",
    "v3.observe(on_change3)\n",
    "\n",
    "display(v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Click here and select \"Run Selected Cell and All Below\" from the \"Run\" menu in the toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HRU color list\n",
    "import random\n",
    "\n",
    "plot_colors = [\n",
    "    \"aliceblue\",\n",
    "    \"aqua\",\n",
    "    \"aquamarine\",\n",
    "    \"azure\",\n",
    "    \"beige\",\n",
    "    \"bisque\",\n",
    "    \"black\",\n",
    "    \"blue\",\n",
    "    \"blueviolet\",\n",
    "    \"brown\",\n",
    "    \"burlywood\",\n",
    "    \"cadetblue\",\n",
    "    \"chartreuse\",\n",
    "    \"chocolate\",\n",
    "    \"coral\",\n",
    "    \"cornflowerblue\",\n",
    "    \"crimson\",\n",
    "    \"cyan\",\n",
    "    \"darkblue\",\n",
    "    \"darkcyan\",\n",
    "    \"darkgoldenrod\",\n",
    "    \"darkgray\",\n",
    "    \"darkgrey\",\n",
    "    \"darkgreen\",\n",
    "    \"darkkhaki\",\n",
    "    \"darkmagenta\",\n",
    "    \"darkolivegreen\",\n",
    "    \"darkorange\",\n",
    "    \"darkorchid\",\n",
    "    \"darkred\",\n",
    "    \"darksalmon\",\n",
    "    \"darkseagreen\",\n",
    "    \"darkslateblue\",\n",
    "    \"darkslategray\",\n",
    "    \"darkslategrey\",\n",
    "    \"darkturquoise\",\n",
    "    \"darkviolet\",\n",
    "    \"deeppink\",\n",
    "    \"deepskyblue\",\n",
    "    \"dodgerblue\",\n",
    "    \"firebrick\",\n",
    "    \"forestgreen\",\n",
    "    \"fuchsia\",\n",
    "    \"gainsboro\",\n",
    "    \"goldenrod\",\n",
    "    \"green\",\n",
    "    \"greenyellow\",\n",
    "    \"honeydew\",\n",
    "    \"hotpink\",\n",
    "    \"indianred\",\n",
    "    \"indigo\",\n",
    "    \"lavender\",\n",
    "    \"lawngreen\",\n",
    "    \"lime\",\n",
    "    \"limegreen\",\n",
    "    \"magenta\",\n",
    "    \"maroon\",\n",
    "    \"mediumaquamarine\",\n",
    "    \"mediumblue\",\n",
    "    \"mediumorchid\",\n",
    "    \"mediumpurple\",\n",
    "    \"mediumseagreen\",\n",
    "    \"mediumslateblue\",\n",
    "    \"mediumspringgreen\",\n",
    "    \"mediumturquoise\",\n",
    "    \"mediumvioletred\",\n",
    "    \"midnightblue\",\n",
    "    \"mintcream\",\n",
    "    \"moccasin\",\n",
    "    \"navy\",\n",
    "    \"olive\",\n",
    "    \"olivedrab\",\n",
    "    \"orange\",\n",
    "    \"orangered\",\n",
    "    \"orchid\",\n",
    "    \"palegreen\",\n",
    "    \"paleturquoise\",\n",
    "    \"palevioletred\",\n",
    "    \"papayawhip\",\n",
    "    \"peachpuff\",\n",
    "    \"peru\",\n",
    "    \"pink\",\n",
    "    \"plum\",\n",
    "    \"powderblue\",\n",
    "    \"purple\",\n",
    "    \"red\",\n",
    "    \"rosybrown\",\n",
    "    \"royalblue\",\n",
    "    \"rebeccapurple\",\n",
    "    \"saddlebrown\",\n",
    "    \"salmon\",\n",
    "    \"sandybrown\",\n",
    "    \"seagreen\",\n",
    "    \"sienna\",\n",
    "    \"silver\",\n",
    "    \"skyblue\",\n",
    "    \"slateblue\",\n",
    "    \"slategray\",\n",
    "    \"slategrey\",\n",
    "    \"springgreen\",\n",
    "    \"steelblue\",\n",
    "    \"tan\",\n",
    "    \"teal\",\n",
    "    \"thistle\",\n",
    "    \"tomato\",\n",
    "    \"turquoise\",\n",
    "    \"violet\",\n",
    "    \"wheat\",\n",
    "    \"yellowgreen\",\n",
    "]\n",
    "# random.shuffle(plot_colors)\n",
    "random.Random(4).shuffle(plot_colors)\n",
    "# plot_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for plots\n",
    "var_colors_dict = {\n",
    "    \"hru_actet\": \"red\",\n",
    "    \"recharge\": \"brown\",\n",
    "    \"net_rain\": \"blue\",\n",
    "    \"net_snow\": \"lightblue\",\n",
    "    \"net_ppt\": \"darkblue\",\n",
    "    \"sroff\": \"lightgreen\",\n",
    "    \"ssres_flow\": \"green\",\n",
    "    \"ssres_flow_vol\": \"green\",\n",
    "    \"gwres_flow\": \"chocolate\",\n",
    "    \"gwres_sink\": \"black\",\n",
    "    \"snowmelt\": \"mediumpurple\",\n",
    "    \"gwres_stor\": \"darkgreen\",\n",
    "    \"gwres_stor_change\": \"darkgreen\",\n",
    "    \"ssres_stor\": \"green\",\n",
    "    \"unused_potet\": \"orange\",\n",
    "}\n",
    "\n",
    "# 'legendonly'\n",
    "leg_only_dict = {\n",
    "    \"hru_actet\": \"legendonly\",\n",
    "    \"recharge\": \"legendonly\",\n",
    "    \"net_rain\": \"legendonly\",\n",
    "    \"net_snow\": \"legendonly\",\n",
    "    \"net_ppt\": True,\n",
    "    \"sroff\": True,\n",
    "    \"ssres_flow\": \"legendonly\",\n",
    "    \"ssres_flow_vol\": \"legendonly\",\n",
    "    \"gwres_flow\": True,\n",
    "    \"gwres_sink\": \"legendonly\",\n",
    "    \"snowmelt\": \"legendonly\",\n",
    "    \"gwres_stor\": \"legendonly\",\n",
    "    \"gwres_stor_change\": \"legendonly\",\n",
    "    \"ssres_stor\": \"legendonly\",\n",
    "    \"unused_potet\": \"legendonly\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poi_id_sel:\n",
    "    hru_list = hru_poi_dict[\n",
    "        poi_id_sel\n",
    "    ]  # returns a list of all upstream contributing hrus\n",
    "\n",
    "    fig = plotly.subplots.make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        shared_xaxes=\"columns\",\n",
    "        # shared_yaxes = 'columns',\n",
    "        start_cell=\"top-left\",\n",
    "        vertical_spacing=0.1,\n",
    "        y_title=f\"{output_var_sel}, {da.units}\",\n",
    "        subplot_titles=[\n",
    "            \"Annual mean\",\n",
    "            \"Monthly mean\",\n",
    "            \"Daily\",\n",
    "        ],\n",
    "        specs=[\n",
    "            [{\"type\": \"scatter\"}],\n",
    "            [{\"type\": \"scatter\"}],\n",
    "            [{\"type\": \"scatter\"}],\n",
    "        ],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title_text=f'The NHM simulated HRU {output_var_sel} for basin <br> {poi_id_sel}, {poi_df.loc[poi_df.poi_id == poi_id_sel, \"poi_name\"].values[0]}',  #\n",
    "        width=900,\n",
    "        height=700,\n",
    "        legend=dict(orientation=\"v\", yanchor=\"top\", y=1, xanchor=\"right\", x=10.0),\n",
    "        # legend_tracegroupgap = 5,\n",
    "        font=dict(family=\"Arial\", size=14, color=\"#7f7f7f\"),  # font color\n",
    "        paper_bgcolor=\"linen\",\n",
    "        plot_bgcolor=\"white\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_automargin=True,\n",
    "        title_font_color=\"black\",\n",
    "        title_font_size=20,\n",
    "        title_x=0.5,\n",
    "        title_y=0.945,\n",
    "        title_xref=\"container\",\n",
    "        title_xanchor=\"center\",\n",
    "    )\n",
    "\n",
    "    # fig.update_xaxes(range = [daily_plot_df.index[0], daily_plot_df.index[-1]])\n",
    "\n",
    "    fig.update_layout(font_color=\"black\")\n",
    "    fig.update_layout(legend={\"title\": \"Area\"})\n",
    "\n",
    "    fig.update_xaxes(ticks=\"inside\", tickwidth=2, tickcolor=\"black\", ticklen=10)\n",
    "    fig.update_yaxes(ticks=\"inside\", tickwidth=2, tickcolor=\"black\", ticklen=10)\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\"\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\"\n",
    "    )\n",
    "\n",
    "    fig.update_traces(hovertemplate=None)\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "    fig.update_layout(\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"linen\",\n",
    "            font_size=13,\n",
    "            font_family=\"Rockwell\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ######################################################\n",
    "\n",
    "    annual_fig = go.Figure()\n",
    "\n",
    "    # subset to selcted gage one gage\n",
    "    df_basin = df_output_var_annual_basin.loc[\n",
    "        df_output_var_annual_basin[\"nhm_id\"].isin(hru_poi_dict[poi_id_sel])\n",
    "    ]\n",
    "    df_basin.set_index(\n",
    "        [\"time\", \"nhm_id\"], inplace=True, drop=True\n",
    "    )  # resets the index to that new value and type\n",
    "\n",
    "    # Calculate basin recharge from individual HRU contributions for plotting\n",
    "    df_basin_plot1 = df_basin.groupby(level=\"time\").sum()\n",
    "    df_basin_plot1[\"output_var\"] = df_basin_plot1[\"vol\"] / df_basin_plot1[\"hru_area\"]\n",
    "\n",
    "    annual_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_basin_plot1.index,\n",
    "            y=(df_basin_plot1.output_var).ravel().tolist(),\n",
    "            mode=\"lines\",\n",
    "            name=f\"Drainage area\",\n",
    "            showlegend=True,\n",
    "            legendgroup=\"poi_basin\",\n",
    "            # marker=dict(color='lightblue'),\n",
    "            line=dict(\n",
    "                color=\"lightblue\",\n",
    "                width=5,\n",
    "                # dash='dot'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for (\n",
    "        value\n",
    "    ) in (\n",
    "        hru_list\n",
    "    ):  # I fixed this below to read right from the xarray, need to fix the hru_list as well.\n",
    "        hru_id_sel = value\n",
    "        color_sel = hru_list.index(hru_id_sel)\n",
    "        ds_sub = (\n",
    "            output_var_annual.where((output_var_annual.nhm_id == hru_id_sel), drop=True)\n",
    "        ).sel(\n",
    "            time=slice(plot_start_date, plot_end_date)\n",
    "        )  # have to fix to subset to new date range\n",
    "        annual_fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=ds_sub.time,\n",
    "                y=(ds_sub.values).ravel().tolist(),\n",
    "                mode=\"lines\",\n",
    "                name=f\"HRU {hru_id_sel}\",\n",
    "                showlegend=True,\n",
    "                visible=\"legendonly\",\n",
    "                legendgroup=hru_id_sel,\n",
    "                # marker=dict(color=plot_colors[color_sel]),\n",
    "                line=dict(\n",
    "                    color=plot_colors[color_sel],\n",
    "                    width=2,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    monthly_fig = go.Figure()\n",
    "\n",
    "    # subset to selcted gage one gage\n",
    "    df_basin = df_output_var_monthly_basin.loc[\n",
    "        df_output_var_monthly_basin[\"nhm_id\"].isin(hru_poi_dict[poi_id_sel])\n",
    "    ]\n",
    "    df_basin.set_index(\n",
    "        [\"time\", \"nhm_id\"], inplace=True, drop=True\n",
    "    )  # resets the index to that new value and type\n",
    "\n",
    "    # Calculate basin recharge from individual HRU contributions for plotting\n",
    "    df_basin_plot1 = df_basin.groupby(level=\"time\").sum()\n",
    "    df_basin_plot1[\"output_var\"] = df_basin_plot1[\"vol\"] / df_basin_plot1[\"hru_area\"]\n",
    "\n",
    "    monthly_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_basin_plot1.index,\n",
    "            y=(df_basin_plot1.output_var).ravel().tolist(),\n",
    "            mode=\"lines\",\n",
    "            name=poi_id_sel,\n",
    "            showlegend=False,\n",
    "            legendgroup=\"poi_basin\",\n",
    "            # marker=dict(color='lightblue'),\n",
    "            line=dict(\n",
    "                color=\"lightblue\",\n",
    "                width=5,\n",
    "                # dash='dot'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for (\n",
    "        value\n",
    "    ) in (\n",
    "        hru_list\n",
    "    ):  # I fixed this below to read right from the xarray, need to fix the hru_list as well.\n",
    "        hru_id_sel = value\n",
    "        color_sel = hru_list.index(hru_id_sel)\n",
    "        ds_sub = (\n",
    "            output_var_monthly.where(\n",
    "                (output_var_monthly.nhm_id == hru_id_sel), drop=True\n",
    "            )\n",
    "        ).sel(time=slice(plot_start_date, plot_end_date))\n",
    "        monthly_fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=ds_sub.time,\n",
    "                y=(ds_sub.values).ravel().tolist(),\n",
    "                mode=\"lines\",\n",
    "                name=hru_id_sel,\n",
    "                showlegend=False,\n",
    "                visible=\"legendonly\",\n",
    "                legendgroup=hru_id_sel,\n",
    "                # marker=dict(color=plot_colors[color_sel]),\n",
    "                line=dict(\n",
    "                    color=plot_colors[color_sel],\n",
    "                    width=2,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    daily_fig = go.Figure()\n",
    "\n",
    "    # subset to selcted gage one gage\n",
    "    df_basin = df_output_var_daily_basin.loc[\n",
    "        df_output_var_daily_basin[\"nhm_id\"].isin(hru_poi_dict[poi_id_sel])\n",
    "    ]\n",
    "    df_basin.set_index(\n",
    "        [\"time\", \"nhm_id\"], inplace=True, drop=True\n",
    "    )  # resets the index to that new value and type\n",
    "\n",
    "    # Calculate basin recharge from individual HRU contributions for plotting\n",
    "    df_basin_plot1 = df_basin.groupby(level=\"time\").sum()\n",
    "    df_basin_plot1[\"output_var\"] = df_basin_plot1[\"vol\"] / df_basin_plot1[\"hru_area\"]\n",
    "\n",
    "    daily_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_basin_plot1.index,\n",
    "            y=(df_basin_plot1.output_var).ravel().tolist(),\n",
    "            mode=\"lines\",\n",
    "            name=poi_id_sel,\n",
    "            showlegend=False,\n",
    "            legendgroup=\"poi_basin\",\n",
    "            # marker=dict(color='lightblue'),\n",
    "            line=dict(\n",
    "                color=\"lightblue\",\n",
    "                width=5,\n",
    "                # dash='dot'\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for (\n",
    "        value\n",
    "    ) in (\n",
    "        hru_list\n",
    "    ):  # I fixed this below to read right from the xarray, need to fix the hru_list as well.\n",
    "        hru_id_sel = value\n",
    "        color_sel = hru_list.index(hru_id_sel)\n",
    "        ds_sub = (\n",
    "            output_var_daily.where((output_var_daily.nhm_id == hru_id_sel), drop=True)\n",
    "        ).sel(time=slice(plot_start_date, plot_end_date))\n",
    "        daily_fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=ds_sub.time,\n",
    "                y=(ds_sub.values).ravel().tolist(),\n",
    "                mode=\"lines\",\n",
    "                name=hru_id_sel,\n",
    "                showlegend=False,\n",
    "                visible=\"legendonly\",\n",
    "                legendgroup=hru_id_sel,\n",
    "                # marker=dict(color=plot_colors[color_sel]),\n",
    "                line=dict(\n",
    "                    color=plot_colors[color_sel],\n",
    "                    width=2,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for t in annual_fig.data:\n",
    "        fig.append_trace(t, row=1, col=1)\n",
    "\n",
    "    for t in monthly_fig.data:\n",
    "        fig.append_trace(t, row=2, col=1)\n",
    "\n",
    "    for t in daily_fig.data:\n",
    "        fig.append_trace(t, row=3, col=1)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poi_id_sel:\n",
    "    fig = plotly.subplots.make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        shared_xaxes=\"columns\",\n",
    "        # shared_yaxes = 'columns',\n",
    "        start_cell=\"top-left\",\n",
    "        vertical_spacing=0.1,\n",
    "        y_title=\"Water flux, cubic-feet per second\",\n",
    "        subplot_titles=[\n",
    "            \"Annual mean\",\n",
    "            \"Monthly mean\",\n",
    "            \"Daily\",\n",
    "        ],\n",
    "        specs=[\n",
    "            [{\"type\": \"scatter\"}],\n",
    "            [{\"type\": \"scatter\"}],\n",
    "            [{\"type\": \"scatter\"}],\n",
    "        ],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title_text=f'The NHM basin water budget flux rates for <br> {poi_id_sel}, {poi_df.loc[poi_df.poi_id == poi_id_sel, \"poi_name\"].values[0]}',  #\n",
    "        width=900,\n",
    "        height=700,\n",
    "        legend=dict(orientation=\"v\", yanchor=\"top\", y=1, xanchor=\"right\", x=10.0),\n",
    "        # legend_tracegroupgap = 5,\n",
    "        font=dict(family=\"Arial\", size=14, color=\"#7f7f7f\"),  # font color\n",
    "        paper_bgcolor=\"linen\",\n",
    "        plot_bgcolor=\"white\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_automargin=True,\n",
    "        title_font_color=\"black\",\n",
    "        title_font_size=20,\n",
    "        title_x=0.5,\n",
    "        title_y=0.945,\n",
    "        title_xref=\"container\",\n",
    "        title_xanchor=\"center\",\n",
    "    )\n",
    "\n",
    "    # fig.update_xaxes(range = [daily_plot_df.index[0], daily_plot_df.index[-1]])\n",
    "\n",
    "    fig.update_layout(font_color=\"black\")\n",
    "    fig.update_layout(\n",
    "        legend={\"title\": \"NHM output variable\"}\n",
    "    )  # <--- add only this line\n",
    "\n",
    "    fig.update_xaxes(ticks=\"inside\", tickwidth=2, tickcolor=\"black\", ticklen=10)\n",
    "    fig.update_yaxes(ticks=\"inside\", tickwidth=2, tickcolor=\"black\", ticklen=10)\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\"\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\"\n",
    "    )\n",
    "\n",
    "    fig.update_traces(hovertemplate=None)\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "    fig.update_layout(\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"linen\",\n",
    "            font_size=13,\n",
    "            font_family=\"Rockwell\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    daily_fig = go.Figure()\n",
    "    annual_fig = go.Figure()\n",
    "    monthly_fig = go.Figure()\n",
    "    ######################################################\n",
    "    for var in output_var_list:\n",
    "        color_sel = var_colors_dict[var]\n",
    "        leg_only = leg_only_dict[var]\n",
    "\n",
    "        # JLM TODO: remove this block\n",
    "        with xr.open_dataset(custom_output_file) as model_output:\n",
    "            output_var1 = model_output.sel(time=slice(plot_start_date, plot_end_date))\n",
    "            ##################################################\n",
    "            output_var_daily1 = getattr(output_var1, var)\n",
    "            output_var_annual1 = (\n",
    "                getattr(output_var1, var).resample(time=\"A-SEP\").mean()\n",
    "            )  # Water year\n",
    "            output_var_monthly1 = (\n",
    "                getattr(output_var1, var).resample(time=\"m\").mean()\n",
    "            )  # monthly\n",
    "\n",
    "        # JLM TODO: keep this block\n",
    "        with xr.load_dataarray(out_dir / f\"{var}.nc\") as da:\n",
    "            # these machinations are to keep downstream things as they were before some refactoring\n",
    "            da = da.to_dataset().rename_dims({\"nhm_id\": \"nhru\"})[da.name]\n",
    "            output_var_daily2 = da.sel(time=slice(plot_start_date, plot_end_date))\n",
    "            output_var_monthly2 = output_var_daily2.resample(time=\"m\").mean()\n",
    "            # Water year annual\n",
    "            output_var_annual2 = output_var_daily2.resample(time=\"A-SEP\").mean()\n",
    "\n",
    "        # JLM TODO: remove this block\n",
    "        xr.testing.assert_equal(output_var_daily1, output_var_daily2)\n",
    "        xr.testing.assert_equal(output_var_monthly1, output_var_monthly2)\n",
    "        xr.testing.assert_equal(output_var_annual1, output_var_annual2)\n",
    "\n",
    "        # JLM TODO: Remove this. This is here to demonstrated that the above runs fine \n",
    "        # while running after this causes a kernel restart. This happens even with the \n",
    "        # custom_output_file in-place.\n",
    "        adsf\n",
    "        \n",
    "        # Create a dataframe of MONTHLY recharge values for each HRU\n",
    "        ds_output_var_monthly_basin1 = output_var_monthly1.copy()\n",
    "        df_output_var_monthly_basin1 = ds_output_var_monthly_basin1.to_dataframe(\n",
    "            dim_order=[\"time\", \"nhru\"]\n",
    "        )\n",
    "        df_output_var_monthly_basin1.reset_index(inplace=True, drop=False)\n",
    "        df_output_var_monthly_basin1.rename(columns={var: \"output_var\"}, inplace=True)\n",
    "\n",
    "        # add the HRU area to the dataframe\n",
    "        df_output_var_monthly_basin1 = df_output_var_monthly_basin1.merge(\n",
    "            hru_area_df, how=\"left\", right_index=True, left_on=\"nhm_id\"\n",
    "        )\n",
    "\n",
    "        # Add output_var volume to the dataframe\n",
    "        df_output_var_monthly_basin1[\"vol\"] = (\n",
    "            df_output_var_monthly_basin1[\"output_var\"]\n",
    "            * (df_output_var_monthly_basin1[\"hru_area\"] * 6272640)\n",
    "        ) / (12 * 12 * 12)\n",
    "        df_output_var_monthly_basin1[\"cfs\"] = (\n",
    "            (\n",
    "                df_output_var_monthly_basin1[\"output_var\"]\n",
    "                * (df_output_var_monthly_basin1[\"hru_area\"] * 6272640)\n",
    "            )\n",
    "            / (12 * 12 * 12)\n",
    "        ) / 86400\n",
    "\n",
    "        # Drop unneeded columns\n",
    "        df_output_var_monthly_basin1.drop(columns=[\"nhru\"], inplace=True)\n",
    "\n",
    "        # Create a dataframe of Daily recharge values for each HRU\n",
    "        ds_output_var_daily_basin1 = output_var_daily1.copy()\n",
    "        df_output_var_daily_basin1 = ds_output_var_daily_basin1.to_dataframe(\n",
    "            dim_order=[\"time\", \"nhru\"]\n",
    "        )\n",
    "        df_output_var_daily_basin1.reset_index(inplace=True, drop=False)\n",
    "        df_output_var_daily_basin1.rename(columns={var: \"output_var\"}, inplace=True)\n",
    "\n",
    "        # add the HRU area to the dataframe\n",
    "        df_output_var_daily_basin1 = df_output_var_daily_basin1.merge(\n",
    "            hru_area_df, how=\"left\", right_index=True, left_on=\"nhm_id\"\n",
    "        )\n",
    "\n",
    "        # Add recharge volume to the dataframe\n",
    "        df_output_var_daily_basin1[\"vol\"] = (\n",
    "            df_output_var_daily_basin1[\"output_var\"]\n",
    "            * (df_output_var_daily_basin1[\"hru_area\"] * 6272640)\n",
    "        ) / (12 * 12 * 12)\n",
    "        df_output_var_daily_basin1[\"cfs\"] = (\n",
    "            (\n",
    "                df_output_var_daily_basin1[\"output_var\"]\n",
    "                * (df_output_var_daily_basin1[\"hru_area\"] * 6272640)\n",
    "            )\n",
    "            / (12 * 12 * 12)\n",
    "        ) / 86400\n",
    "\n",
    "        # Drop unneeded columns\n",
    "        df_output_var_daily_basin1.drop(columns=[\"nhru\"], inplace=True)\n",
    "\n",
    "        # Create a dataframe of ANNUAL recharge values for each HRU\n",
    "        ds_output_var_annual_basin1 = output_var_annual1.copy()\n",
    "        df_output_var_annual_basin1 = ds_output_var_annual_basin1.to_dataframe(\n",
    "            dim_order=[\"time\", \"nhru\"]\n",
    "        )\n",
    "        df_output_var_annual_basin1.reset_index(inplace=True, drop=False)\n",
    "        df_output_var_annual_basin1.rename(columns={var: \"output_var\"}, inplace=True)\n",
    "\n",
    "        df_output_var_annual_basin1 = df_output_var_annual_basin1.merge(\n",
    "            hru_area_df, how=\"left\", right_index=True, left_on=\"nhm_id\"\n",
    "        )\n",
    "\n",
    "        # Add recharge volume to the dataframe\n",
    "        df_output_var_annual_basin1[\"vol\"] = (\n",
    "            df_output_var_annual_basin1[\"output_var\"]\n",
    "            * (df_output_var_annual_basin1[\"hru_area\"] * 6272640)\n",
    "        ) / (\n",
    "            12 * 12 * 12\n",
    "        )  # Cubic-feet\n",
    "        df_output_var_annual_basin1[\"cfs\"] = (\n",
    "            (\n",
    "                df_output_var_annual_basin1[\"output_var\"]\n",
    "                * (df_output_var_annual_basin1[\"hru_area\"] * 6272640)\n",
    "            )\n",
    "            / (12 * 12 * 12)\n",
    "        ) / 86400  # Cubic-feet/sec\n",
    "\n",
    "        # Drop unneeded columns\n",
    "        df_output_var_annual_basin1.drop(columns=[\"nhru\"], inplace=True)\n",
    "\n",
    "        ###################################################################################################################\n",
    "\n",
    "        # subset to selcted gage one gage\n",
    "        df_basin1 = df_output_var_annual_basin1.loc[\n",
    "            df_output_var_annual_basin1[\"nhm_id\"].isin(hru_poi_dict[poi_id_sel])\n",
    "        ]\n",
    "        df_basin1.set_index(\n",
    "            [\"time\", \"nhm_id\"], inplace=True, drop=True\n",
    "        )  # resets the index to that new value and type\n",
    "\n",
    "        # Calculate basin recharge from individual HRU contributions for plotting\n",
    "        df_basin_plot1 = df_basin1.groupby(level=\"time\").sum()\n",
    "        df_basin_plot1[\"output_var\"] = (df_basin_plot1[\"vol\"] * 12 * 12 * 12) / (\n",
    "            df_basin_plot1[\"hru_area\"] * 6272640\n",
    "        )  # back to inches\n",
    "        # df_basin_plot['cfs'] =\n",
    "\n",
    "        annual_fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_basin_plot1.index,\n",
    "                y=(df_basin_plot1.cfs).ravel().tolist(),\n",
    "                # x=year_list,\n",
    "                # y= (gdf.loc[gdf.nhm_id == hru_id_sel, year_list].values).ravel().tolist(),\n",
    "                mode=\"lines\",\n",
    "                name=var,\n",
    "                visible=leg_only,\n",
    "                showlegend=True,\n",
    "                legendgroup=var,\n",
    "                # marker=dict(color='lightblue'),\n",
    "                line_shape=\"vh\",\n",
    "                line=dict(\n",
    "                    color=color_sel,\n",
    "                    width=2,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # subset to selcted gage one gage\n",
    "        df_basin1 = df_output_var_monthly_basin1.loc[\n",
    "            df_output_var_monthly_basin1[\"nhm_id\"].isin(hru_poi_dict[poi_id_sel])\n",
    "        ]\n",
    "        df_basin1.set_index(\n",
    "            [\"time\", \"nhm_id\"], inplace=True, drop=True\n",
    "        )  # resets the index to that new value and type\n",
    "\n",
    "        # Calculate basin recharge from individual HRU contributions for plotting\n",
    "        df_basin_plot1 = df_basin1.groupby(level=\"time\").sum()\n",
    "        df_basin_plot1[\"output_var\"] = (df_basin_plot1[\"vol\"] * 12 * 12 * 12) / (\n",
    "            df_basin_plot1[\"hru_area\"] * 6272640\n",
    "        )  # back to inches\n",
    "\n",
    "        monthly_fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_basin_plot1.index,\n",
    "                y=(df_basin_plot1.cfs).ravel().tolist(),\n",
    "                # x=year_list,\n",
    "                # y= (gdf.loc[gdf.nhm_id == hru_id_sel, year_list].values).ravel().tolist(),\n",
    "                mode=\"lines\",\n",
    "                name=var,\n",
    "                visible=leg_only,\n",
    "                showlegend=False,\n",
    "                legendgroup=var,\n",
    "                # marker=dict(color='lightblue'),\n",
    "                line_shape=\"vh\",\n",
    "                line=dict(\n",
    "                    color=color_sel,\n",
    "                    width=2,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # subset to selcted gage one gage\n",
    "        df_basin1 = df_output_var_daily_basin1.loc[\n",
    "            df_output_var_daily_basin1[\"nhm_id\"].isin(hru_poi_dict[poi_id_sel])\n",
    "        ]\n",
    "        df_basin1.set_index(\n",
    "            [\"time\", \"nhm_id\"], inplace=True, drop=True\n",
    "        )  # resets the index to that new value and type\n",
    "\n",
    "        # Calculate basin recharge from individual HRU contributions for plotting\n",
    "        df_basin_plot1 = df_basin1.groupby(level=\"time\").sum()\n",
    "        df_basin_plot1[\"output_var\"] = (df_basin_plot1[\"vol\"] * 12 * 12 * 12) / (\n",
    "            df_basin_plot1[\"hru_area\"] * 6272640\n",
    "        )  # back to inches\n",
    "\n",
    "        daily_fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_basin_plot1.index,\n",
    "                y=(df_basin_plot1.cfs).ravel().tolist(),\n",
    "                # x=year_list,\n",
    "                # y= (gdf.loc[gdf.nhm_id == hru_id_sel, year_list].values).ravel().tolist(),\n",
    "                mode=\"lines\",\n",
    "                name=var,\n",
    "                visible=leg_only,\n",
    "                showlegend=False,\n",
    "                legendgroup=var,\n",
    "                # marker=dict(color='lightblue'),\n",
    "                line_shape=\"vh\",\n",
    "                line=dict(\n",
    "                    color=color_sel,\n",
    "                    width=2,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for t in annual_fig.data:\n",
    "        fig.append_trace(t, row=1, col=1)\n",
    "\n",
    "    for t in monthly_fig.data:\n",
    "        fig.append_trace(t, row=2, col=1)\n",
    "\n",
    "    for t in daily_fig.data:\n",
    "        fig.append_trace(t, row=3, col=1)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
