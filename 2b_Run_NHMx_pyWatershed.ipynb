{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec88cf-ea91-4ef1-ba16-ace9d78c9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"0a_Workspace_setup.ipynb\"\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226d8fa-2d0a-4fe4-a52d-b44645452694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywatershed as pws\n",
    "\n",
    "# sys.path.append(\"../scripts/\")\n",
    "# from pest_utils import pars_to_tpl_entries\n",
    "# sys.path.append(\"../dependencies/\")\n",
    "# import pyemu\n",
    "\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d85ea6-aa33-44ed-bcd7-c0ab01560572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_folder_name = '20240619_v1.1_gm_WallaWalla_byHWobs_custom_cal'# This line will be edited by the user\n",
    "# root_dir = pl.Path('../').resolve()\n",
    "# notebook_dir = pl.Path('./').resolve()\n",
    "# model_dir = pl.Path(root_dir/ f'{model_folder_name}').resolve()\n",
    "\n",
    "# print(f'The root directory is {root_dir}')\n",
    "# print(f'The notebook directory is {notebook_dir}')\n",
    "# print(f'The model directory is {model_dir}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef9eea-4c69-426d-9276-551f4c07eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First make an output directory should one not exist\n",
    "# if not (model_dir / 'output').exists():\n",
    "#         (model_dir / 'output').mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbaa644-a220-4c62-a898-523ac33efda4",
   "metadata": {},
   "source": [
    "### Writes the parameter file as a json fileÂ¶\n",
    "#### This makes the par file compatible with our current notebooks for pws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a60eed-8f8a-41b3-86c6-f4d7ecbceae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Setting the model parameter file name-- this set to pyWatershed custom output file, but may choose another NHM file from Bandit extraction, eg. byHRU.\n",
    "\n",
    "pardat = pws.parameters.PrmsParameters.load(\n",
    "    param_filename\n",
    ")  # load parameter file from extraction\n",
    "\n",
    "# pardat.parameters_to_json(model_dir /\"parameters.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a51b62-88a1-41e8-96a8-2e6cd54f3c53",
   "metadata": {},
   "source": [
    "#### Some useful pws checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170008ca-a25e-4e56-bd0a-2cf46df554c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pws.PRMSCanopy.get_variables()\n",
    "# pws.PRMSSnow.get_variables()\n",
    "# pws.PRMSRunoff.get_variables()\n",
    "# pws.PRMSSoilzone.get_variables()\n",
    "# pws.PRMSGroundwater.get_variables()\n",
    "# pws.PRMSChannel.get_variables()\n",
    "# pws.PRMSStarfit.get_variables()\n",
    "\n",
    "# pws.meta.find_variables([pws.PRMSChannel.get_variables()[2]])\n",
    "\n",
    "# Helpful table for explaining variables https://water.usgs.gov/water-resources/software/PRMS/PRMS_tables_5.2.1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a91cf-cfbf-425e-b171-2897b32c1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.meta.find_variables([pws.PRMSChannel.get_variables()[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c79ddb-5133-4eb9-8ceb-2ee7217966b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.PRMSAtmosphere.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839e34a-2353-4f87-8e47-75d9b03457d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pws.meta.find_variables([pws.PRMSAtmosphere.get_variables()[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493702d8-2dd8-46a7-a6a3-0ae9b392a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.PRMSCanopy.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38136ae-66fa-475e-8bd1-f03fa7f8193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.meta.find_variables([pws.PRMSCanopy.get_variables()[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfa5a2-ab5d-4896-8d05-bb9dec89e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pws.PRMSSnow.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754591c-38ba-49d7-800b-c6da30b60d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.PRMSAtmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace14adb-e8ce-49df-813b-1338c4876010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.meta.find_variables([pws.PRMSSnow.get_variables()[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e311ee-d072-4bb7-86a9-6445d8d4c88d",
   "metadata": {},
   "source": [
    "### Custom Run the Model output loop and default output loop\n",
    "The default loop will output the PyWatershed standard output variables only and outputs each variable as a .nc file.\n",
    "The cusom loop uses the standartds to calculate other output variables (known to PyWatershed) and creates one .nc file will all standard and custom variables and metadata, with special dimension for pois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad30ca5-4cc3-4884-a605-4da17d9f4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JLM TODO: move to markdown\n",
    "# pywatershed  requires the siolzone variable \"pref_flow_infil_frac\" to be\n",
    "# present where as PRMS does not. If the variable is not in the PRMS files\n",
    "# we must add it to the parmaeter as all zeros before passing the parameters\n",
    "# to the model.\n",
    "params = pws.parameters.PrmsParameters.load(param_filename)\n",
    "if not \"pref_flow_infil_frac\" in params.parameters.keys():\n",
    "    # Parameter objects are not directly editable in pywatershed,\n",
    "    # so we export to an equivalent object we can edit, in this case\n",
    "    # an xarray dataset, then we convert back\n",
    "    params_ds = params.to_xr_ds()\n",
    "    params_ds[\"pref_flow_infil_frac\"] = params_ds.pref_flow_den[:] * 0.0\n",
    "    params = pws.parameters.PrmsParameters.from_ds(params_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5767ed3-5c65-4a26-a199-2e71ad9ad906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # do the model custom output\n",
    "# control = pws.Control.load_prms(\n",
    "#     model_dir / control_file_name, warn_unused_options=False\n",
    "# )\n",
    "\n",
    "# control.options = control.options | {\n",
    "#     \"input_dir\": model_dir,\n",
    "#     \"budget_type\": None,\n",
    "#     \"verbosity\": 0,\n",
    "#     \"calc_method\": \"numba\",\n",
    "#     \"netcdf_output_var_names\": None,\n",
    "#     \"netcdf_output_dir\": None,\n",
    "# }\n",
    "\n",
    "# model = pws.Model(\n",
    "#     [\n",
    "#         pws.PRMSSolarGeometry,\n",
    "#         pws.PRMSAtmosphere,\n",
    "#         pws.PRMSCanopy,\n",
    "#         pws.PRMSSnow,\n",
    "#         pws.PRMSRunoff,\n",
    "#         pws.PRMSSoilzone,\n",
    "#         pws.PRMSGroundwater,\n",
    "#         pws.PRMSChannel,\n",
    "#     ],\n",
    "#     control=control,\n",
    "#     parameters=params,\n",
    "# )\n",
    "\n",
    "# # /////////////////////////////////\n",
    "# # specfications: what we want this to look like to the user\n",
    "# var_list = [\n",
    "#     \"hru_actet\",\n",
    "#     # \"potet\",\n",
    "#     # \"tmaxf\",\n",
    "#     \"seg_outflow\",\n",
    "#     \"recharge\",\n",
    "#     # \"snowcov_area\",\n",
    "#     # \"soil_rechr\",\n",
    "#     \"net_rain\",\n",
    "#     \"net_snow\",\n",
    "#     \"net_ppt\",\n",
    "#     \"sroff\",  # values in inches for area weighted averaging\n",
    "#     \"ssres_flow\",  # values in inches for area weighted averaging\n",
    "#     \"gwres_flow\",  # values in inches for area weighted averaging\n",
    "#     \"gwres_sink\",\n",
    "#     \"snowmelt\",\n",
    "#     \"gwres_stor\",\n",
    "#     \"gwres_stor_change\",\n",
    "#     \"ssres_stor\",\n",
    "#     \"unused_potet\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# # want seg_outflow just on poi_gages\n",
    "# # make it a tuple like the return of np.where\n",
    "# wh_gages = (\n",
    "#     params.parameters[\"poi_gage_segment\"] - 1,\n",
    "# )  # - 1 is related to the indexing in fortran; made a a tuple see above\n",
    "# spatial_subsets = {\n",
    "#     \"poi_gages\": {\n",
    "#         \"coord_name\": \"nhm_seg\",\n",
    "#         \"indices\": wh_gages,\n",
    "#         \"new_coord\": params.parameters[\"poi_gage_id\"],\n",
    "#         \"variables\": [\n",
    "#             \"seg_outflow\",\n",
    "#         ],  # can add any other var with same coord here,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "\n",
    "# # A novel, diagnostic variable\n",
    "# def sum_hru_flows(\n",
    "#     sroff_vol, ssres_flow_vol, gwres_flow_vol\n",
    "# ):  # These vars used to calc, do not need to be in the var list\n",
    "#     return sroff_vol + ssres_flow_vol + gwres_flow_vol\n",
    "\n",
    "\n",
    "# diagnostic_var_dict = {\n",
    "#     \"hru_streamflow_out\": {\n",
    "#         \"inputs\": [\"sroff_vol\", \"ssres_flow_vol\", \"gwres_flow_vol\"],\n",
    "#         \"function\": sum_hru_flows,\n",
    "#         \"like_var\": \"sroff_vol\",\n",
    "#         \"metadata\": {\n",
    "#             \"desc\": \"Total volume to stream network from each HRU\",\n",
    "#             \"units\": \"cubic feet\",\n",
    "#         },\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # TODO: specify subsets in time\n",
    "# # TODO: specify different output files\n",
    "\n",
    "# # /////////////////////////////////\n",
    "# # code starts here\n",
    "\n",
    "# out_subset_ds = xr.Dataset()\n",
    "\n",
    "# needed_vars = var_list + [\n",
    "#     var for key, val in diagnostic_var_dict.items() for var in val[\"inputs\"]\n",
    "# ]\n",
    "# needed_metadata = pws.meta.get_vars(needed_vars)\n",
    "# dims = set([dim for val in needed_metadata.values() for dim in val[\"dims\"]])\n",
    "\n",
    "# subset_vars = [var for key, val in spatial_subsets.items() for var in val[\"variables\"]]\n",
    "\n",
    "# var_subset_key = {\n",
    "#     var: subkey\n",
    "#     for var in subset_vars\n",
    "#     for subkey in spatial_subsets.keys()\n",
    "#     if var in spatial_subsets[subkey][\"variables\"]\n",
    "# }\n",
    "\n",
    "# diagnostic_vars = list(diagnostic_var_dict.keys())\n",
    "\n",
    "# # solve the processes for each variable\n",
    "# var_proc = {\n",
    "#     var: proc_key\n",
    "#     for var in needed_vars\n",
    "#     for proc_key, proc_val in model.processes.items()\n",
    "#     if var in proc_val.get_variables()\n",
    "# }\n",
    "\n",
    "# time_coord = np.arange(\n",
    "#     control.start_time, control.end_time + control.time_step, dtype=\"datetime64[D]\"\n",
    "# )\n",
    "# n_time_steps = len(time_coord)\n",
    "# out_subset_ds[\"time\"] = xr.Variable([\"time\"], time_coord)\n",
    "# out_subset_ds = out_subset_ds.set_coords(\"time\")\n",
    "\n",
    "# # annoying to have to hard-code this\n",
    "# dim_coord = {\"nhru\": \"nhm_id\", \"nsegment\": \"nhm_seg\"}\n",
    "\n",
    "# ####################################################################################\n",
    "# # declare memory for the outputs\n",
    "# for var in var_list + diagnostic_vars:\n",
    "#     # impostor approach\n",
    "#     orig_diag_var = None\n",
    "#     if var in diagnostic_vars:\n",
    "#         orig_diag_var = var\n",
    "#         var = diagnostic_var_dict[var][\"like_var\"]\n",
    "\n",
    "#     proc = model.processes[var_proc[var]]\n",
    "#     dim_name = needed_metadata[var][\"dims\"][0]\n",
    "#     dim_len = proc._params.dims[dim_name]\n",
    "#     coord_name = dim_coord[dim_name]\n",
    "#     coord_data = proc._params.coords[dim_coord[dim_name]]\n",
    "#     type = needed_metadata[var][\"type\"]\n",
    "\n",
    "#     var_meta = {\n",
    "#         kk: vv for kk, vv in needed_metadata[var].items() if kk in [\"desc\", \"units\"]\n",
    "#     }\n",
    "\n",
    "#     if orig_diag_var is not None:\n",
    "#         var = orig_diag_var\n",
    "#         del var_meta[\"desc\"]\n",
    "#         if \"metadata\" in diagnostic_var_dict[var]:\n",
    "#             var_meta = diagnostic_var_dict[var][\"metadata\"]\n",
    "#         if \"desc\" not in var_meta.keys():\n",
    "#             var_meta[\"desc\"] = \"Custom output diagnostic variable\"\n",
    "\n",
    "#     if var in subset_vars:\n",
    "#         subset_key = var_subset_key[var]\n",
    "#         subset_info = spatial_subsets[subset_key]\n",
    "#         dim_name = f\"n{subset_key}\"\n",
    "#         coord_name = subset_key\n",
    "#         dim_len = len(subset_info[\"indices\"][0])\n",
    "#         coord_data = subset_info[\"new_coord\"]\n",
    "\n",
    "#     if coord_name not in list(out_subset_ds.variables):\n",
    "#         out_subset_ds[coord_name] = xr.DataArray(coord_data, dims=[dim_name])\n",
    "#         out_subset_ds = out_subset_ds.set_coords(coord_name)\n",
    "\n",
    "#     out_subset_ds[var] = xr.Variable(\n",
    "#         [\"time\", dim_name],\n",
    "#         np.full(\n",
    "#             [n_time_steps, dim_len],\n",
    "#             pws.constants.fill_values_dict[np.dtype(type)],\n",
    "#             type,\n",
    "#         ),\n",
    "#     )\n",
    "\n",
    "#     out_subset_ds[var].attrs = var_meta\n",
    "\n",
    "# #########################################################################################\n",
    "# # Is this the model running???? YES\n",
    "# for istep in tqdm(range(n_time_steps)):\n",
    "#     model.advance()\n",
    "#     model.calculate()\n",
    "\n",
    "#     model.output()\n",
    "\n",
    "#     for var in var_list:\n",
    "#         proc = model.processes[var_proc[var]]\n",
    "#         data = proc[var]\n",
    "#         if isinstance(proc[var], pws.base.timeseries.TimeseriesArray):\n",
    "#             data = data.current\n",
    "#         if var not in subset_vars:\n",
    "#             out_subset_ds[var][istep, :] = data\n",
    "#         else:\n",
    "#             indices = spatial_subsets[var_subset_key[var]][\"indices\"]\n",
    "#             out_subset_ds[var][istep, :] = data[indices]\n",
    "\n",
    "#     for diag_key, diag_val in diagnostic_var_dict.items():\n",
    "#         input_dict = {}\n",
    "#         for ii in diag_val[\"inputs\"]:\n",
    "#             proc = model.processes[var_proc[ii]]\n",
    "#             input_dict[ii] = proc[ii]\n",
    "\n",
    "#         out_subset_ds[diag_key][istep, :] = diag_val[\"function\"](\n",
    "#             **input_dict\n",
    "#         )  # this is where the diag_var is actually being calc'd/time step\n",
    "\n",
    "\n",
    "# out_subset_ds.to_netcdf(custom_output_file)\n",
    "# out_subset_ds.close()\n",
    "\n",
    "# del proc, input_dict, model, out_subset_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1a1a0-0ecf-4377-bce8-6826d7f8eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "control = pws.Control.load_prms(\n",
    "    model_dir / control_file_name, warn_unused_options=False\n",
    ")\n",
    "# Sets control options for both cases\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": model_dir,\n",
    "    \"budget_type\": None,\n",
    "    \"verbosity\": 0,\n",
    "    \"calc_method\": \"numba\",\n",
    "}\n",
    "\n",
    "control.options = control.options | {\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"hru_actet\",\n",
    "        \"seg_outflow\",\n",
    "        \"recharge\",\n",
    "        \"net_rain\",\n",
    "        \"net_snow\",\n",
    "        \"net_ppt\",\n",
    "        \"sroff\",\n",
    "        \"ssres_flow\",\n",
    "        \"gwres_flow\",\n",
    "        \"gwres_sink\",\n",
    "        \"snowmelt\",\n",
    "        \"gwres_stor\",\n",
    "        \"gwres_stor_change\",\n",
    "        \"ssres_stor\",\n",
    "        \"unused_potet\",\n",
    "        \"sroff_vol\",\n",
    "        \"ssres_flow_vol\",\n",
    "        \"gwres_flow_vol\",\n",
    "    ],\n",
    "    \"netcdf_output_dir\": out_dir,\n",
    "}\n",
    "\n",
    "model = pws.Model(\n",
    "    [\n",
    "        pws.PRMSSolarGeometry,\n",
    "        pws.PRMSAtmosphere,\n",
    "        pws.PRMSCanopy,\n",
    "        pws.PRMSSnow,\n",
    "        pws.PRMSRunoff,\n",
    "        pws.PRMSSoilzone,\n",
    "        pws.PRMSGroundwater,\n",
    "        pws.PRMSChannel,\n",
    "    ],\n",
    "    control=control,\n",
    "    parameters=params,\n",
    ")\n",
    "\n",
    "\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db62b9-d6e4-4bcd-8420-2793beb4ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "hru_streamflow_out = sum(\n",
    "    xr.load_dataarray(f\"{out_dir / ff}.nc\")\n",
    "    for ff in [\"sroff_vol\", \"ssres_flow_vol\", \"gwres_flow_vol\"]\n",
    ")\n",
    "hru_streamflow_out.to_netcdf(out_dir / \"hru_streamflow_out.nc\")\n",
    "del hru_streamflow_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3c654-7af3-4f87-885a-c9c60c81392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 1 is related to the indexing in fortran; made a a tuple see above\n",
    "wh_gages = (params.parameters[\"poi_gage_segment\"] - 1,)\n",
    "for var in [\"seg_outflow\"]:\n",
    "    data = xr.load_dataarray(f\"{out_dir / var}.nc\")[:, wh_gages[0]]\n",
    "    out_file = f\"{out_dir / var}.nc\"\n",
    "    data.to_netcdf(out_file)\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747051a-f61f-479c-9a1f-868e6e7085ff",
   "metadata": {},
   "source": [
    "### Diagnostic Check\n",
    "#### Checks the custom output against the standard outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668fabf-0784-407c-b825-b8323d681893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_subset_ds = xr.open_dataset(custom_output_file)\n",
    "# custom_vars = set(out_subset_ds.data_vars)\n",
    "# std_vars = {vv.name.split(\".\")[0] for vv in set(out_dir.glob(\"*.nc\"))} - {\n",
    "#     \"model_custom_output\"\n",
    "# }\n",
    "# print(f\"{custom_vars - std_vars}\")\n",
    "# print(f\"{std_vars - custom_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f7809-d252-416c-9ff1-0e73392ab04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_subset_ds = xr.open_dataset(custom_output_file)\n",
    "\n",
    "# # for vv in var_list:\n",
    "# for vv in out_subset_ds:\n",
    "#     default_output_file = out_dir / f\"{vv}.nc\"\n",
    "#     print(str(default_output_file), default_output_file.exists())\n",
    "#     print(\"checking variable: \", vv)\n",
    "#     answer = xr.load_dataarray(default_output_file)\n",
    "\n",
    "#     result = out_subset_ds[vv]\n",
    "\n",
    "#     # if vv in subset_vars:\n",
    "#     #     indices = spatial_subsets[var_subset_key[vv]][\"indices\"]\n",
    "#     #     answer = answer[:, indices[0]]\n",
    "\n",
    "#     np.testing.assert_allclose(answer, result)\n",
    "#     answer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4532f49-5d04-4ecf-913c-cc88ad8cde34",
   "metadata": {},
   "source": [
    "#### Reading the custom output.nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cf15b-a49a-4626-8d7a-25c950a0220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recharge = xr.open_dataarray(out_dir / \"recharge.nc\")\n",
    "seg_outflow = xr.open_dataarray(out_dir / \"seg_outflow.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c121dc-6b86-4a51-ace4-95afdf0fb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ab5cc-9c3a-4448-a4a4-932c51da0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_outflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf591a-cd05-47bd-a2fa-742939dc5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del recharge, seg_outflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dc595-28f0-4d1a-adde-659570fc0a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
