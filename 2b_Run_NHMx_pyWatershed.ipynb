{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec88cf-ea91-4ef1-ba16-ace9d78c9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"0a_Workspace_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226d8fa-2d0a-4fe4-a52d-b44645452694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywatershed as pws\n",
    "#import os\n",
    "import dask\n",
    "\n",
    "\n",
    "#Check to make sure these are really needed\n",
    "from pywatershed.parameters.prms_parameters import JSONParameterEncoder\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "#from pest_utils import pars_to_tpl_entries\n",
    "sys.path.append('../dependencies/')\n",
    "#import pyemu\n",
    "\n",
    "import shutil\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d85ea6-aa33-44ed-bcd7-c0ab01560572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_folder_name = '20240619_v1.1_gm_WallaWalla_byHWobs_custom_cal'# This line will be edited by the user\n",
    "# root_dir = pl.Path('../').resolve()\n",
    "# notebook_dir = pl.Path('./').resolve()\n",
    "# model_dir = pl.Path(root_dir/ f'{model_folder_name}').resolve()\n",
    "\n",
    "# print(f'The root directory is {root_dir}')\n",
    "# print(f'The notebook directory is {notebook_dir}')\n",
    "# print(f'The model directory is {model_dir}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef9eea-4c69-426d-9276-551f4c07eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First make an output directory should one not exist\n",
    "# if not (model_dir / 'output').exists():\n",
    "#         (model_dir / 'output').mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbaa644-a220-4c62-a898-523ac33efda4",
   "metadata": {},
   "source": [
    "### Writes the parameter file as a json fileÂ¶\n",
    "#### This makes the par file compatible with our current notebooks for pws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a60eed-8f8a-41b3-86c6-f4d7ecbceae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Setting the model parameter file name-- this set to pyWatershed custom output file, but may choose another NHM file from Bandit extraction, eg. byHRU.\n",
    "\n",
    "pardat = pws.parameters.PrmsParameters.load(param_filename)#load parameter file from extraction\n",
    "\n",
    "#pardat.parameters_to_json(model_dir /\"parameters.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a51b62-88a1-41e8-96a8-2e6cd54f3c53",
   "metadata": {},
   "source": [
    "#### Some useful pws checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170008ca-a25e-4e56-bd0a-2cf46df554c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#pws.PRMSCanopy.get_variables()\n",
    "#pws.PRMSSnow.get_variables()\n",
    "#pws.PRMSRunoff.get_variables()\n",
    "#pws.PRMSSoilzone.get_variables()\n",
    "#pws.PRMSGroundwater.get_variables()\n",
    "#pws.PRMSChannel.get_variables()\n",
    "#pws.PRMSStarfit.get_variables()\n",
    "\n",
    "#pws.meta.find_variables([pws.PRMSChannel.get_variables()[2]])\n",
    "\n",
    "#Helpful table for explaining variables https://water.usgs.gov/water-resources/software/PRMS/PRMS_tables_5.2.1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a91cf-cfbf-425e-b171-2897b32c1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.meta.find_variables([pws.PRMSChannel.get_variables()[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c79ddb-5133-4eb9-8ceb-2ee7217966b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.PRMSAtmosphere.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839e34a-2353-4f87-8e47-75d9b03457d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pws.meta.find_variables([pws.PRMSAtmosphere.get_variables()[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493702d8-2dd8-46a7-a6a3-0ae9b392a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.PRMSCanopy.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38136ae-66fa-475e-8bd1-f03fa7f8193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.meta.find_variables([pws.PRMSCanopy.get_variables()[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfa5a2-ab5d-4896-8d05-bb9dec89e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pws.PRMSSnow.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754591c-38ba-49d7-800b-c6da30b60d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.PRMSAtmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace14adb-e8ce-49df-813b-1338c4876010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.meta.find_variables([pws.PRMSSnow.get_variables()[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e311ee-d072-4bb7-86a9-6445d8d4c88d",
   "metadata": {},
   "source": [
    "### Custom Run the Model output loop and default output loop\n",
    "#### The default loop will output the PyWatershed standard output variables only and outputs each variable as a .nc file.\n",
    "#### The cusom loop uses the standartds to calculate other output variables (known to PyWatershed) and creates one .nc file will all standard and custom variables and metadata, with special dimension for pois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5767ed3-5c65-4a26-a199-2e71ad9ad906",
   "metadata": {},
   "outputs": [],
   "source": [
    "sttime = time.time()\n",
    "print(\"You will be prompted when the model is finished running in about 5 minutes.\")\n",
    "model_output_netcdf = False\n",
    "\n",
    "#work_dir = root_dir / model_folder_name\n",
    "#out_dir = root_dir/ model_folder_name / 'output'\n",
    "#out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#custom_output_file = out_dir / \"model_custom_output.nc\"\n",
    "#param_file = work_dir / \"myparam.param\" #took out because is in the first notebook now 0a\n",
    "\n",
    "#control = pws.Control.load_prms(model_dir / \"control.default.bandit\", warn_unused_options= False)\n",
    "\n",
    "#Load param and control file into pyWatershed\n",
    "#params = pws.parameters.PrmsParameters.load_from_json(param_file)\n",
    "params = pws.parameters.PrmsParameters.load(param_filename)\n",
    "\n",
    "\n",
    "control = pws.Control.load_prms(model_dir / control_file_name, warn_unused_options= False)\n",
    "#Sets control options for both cases\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": model_dir,\n",
    "    \"budget_type\": None,\n",
    "    \"verbosity\": 0,\n",
    "    \"calc_method\": \"numba\",\n",
    "}\n",
    "\n",
    "if model_output_netcdf:\n",
    "    control.options = control.options | {\n",
    "        \"netcdf_output_var_names\": [\n",
    "            \"hru_actet\",\n",
    "            #\"potet\",\n",
    "            #\"tmaxf\",\n",
    "            \"sroff_vol\",\n",
    "            \"ssres_flow_vol\",\n",
    "            \"gwres_flow_vol\",\n",
    "            \"seg_outflow\",\n",
    "           #\"hru_streamflow_out\",\n",
    "            \"recharge\",\n",
    "            #\"snowcov_area\", \n",
    "            #\"soil_rechr\",\n",
    "            #\"hru_actet\",\n",
    "            \"net_rain\",\n",
    "            \"net_snow\",\n",
    "            \"net_ppt\",\n",
    "            \"sroff\",\n",
    "            \"ssres_flow\",\n",
    "            \"gwres_flow\",\n",
    "            #\"seg_outflow\",\n",
    "            #\"hru_streamflow_out\",\n",
    "            \"gwres_sink\",\n",
    "            \"snowmelt\",\n",
    "            \"gwres_stor\",\n",
    "            \"gwres_stor_change\",\n",
    "            \"ssres_stor\",\n",
    "            \"unused_potet\",\n",
    "        ],\n",
    "        \"netcdf_output_dir\": out_dir,\n",
    "    }\n",
    "else:\n",
    "    control.options = control.options | {\n",
    "        \"netcdf_output_var_names\": None,\n",
    "        \"netcdf_output_dir\": None,\n",
    "    }\n",
    "\n",
    "model = pws.Model(\n",
    "    [\n",
    "        pws.PRMSSolarGeometry,\n",
    "        pws.PRMSAtmosphere,\n",
    "        pws.PRMSCanopy,\n",
    "        pws.PRMSSnow,\n",
    "        pws.PRMSRunoff,\n",
    "        pws.PRMSSoilzone,\n",
    "        pws.PRMSGroundwater,\n",
    "        pws.PRMSChannel,\n",
    "    ],\n",
    "    control=control,\n",
    "    parameters=params,\n",
    ")\n",
    "\n",
    "# Custom model output at selected spatial locations for all times.\n",
    "# Generally, i'd be careful with xarray performance, but just writing at the\n",
    "# end should be fine.\n",
    "# Could move to netcdf4 if performance is a concern.\n",
    "\n",
    "# /////////////////////////////////\n",
    "# specfications: what we want this to look like to the user\n",
    "var_list = [\n",
    "    \"hru_actet\",\n",
    "    #\"potet\",\n",
    "    #\"tmaxf\",\n",
    "    \"seg_outflow\",\n",
    "    \"recharge\",\n",
    "    #\"snowcov_area\",\n",
    "    #\"soil_rechr\",\n",
    "    \"net_rain\",\n",
    "    \"net_snow\",\n",
    "    \"net_ppt\",\n",
    "    \"sroff\",# values in inches for area weighted averaging\n",
    "    \"ssres_flow\",# values in inches for area weighted averaging\n",
    "    \"gwres_flow\",# values in inches for area weighted averaging\n",
    "    \"gwres_sink\",\n",
    "    \"snowmelt\",\n",
    "    \"gwres_stor\",\n",
    "    \"gwres_stor_change\",\n",
    "    \"ssres_stor\",\n",
    "    \"unused_potet\",\n",
    "]\n",
    "\n",
    "\n",
    "# want seg_outflow just on poi_gages\n",
    "# make it a tuple like the return of np.where\n",
    "wh_gages = (params.parameters[\"poi_gage_segment\"] - 1,)# - 1 is related to the indexing in fortran; made a a tuple see above\n",
    "spatial_subsets = {\n",
    "    \"poi_gages\": {\n",
    "        \"coord_name\": \"nhm_seg\",\n",
    "        \"indices\": wh_gages,\n",
    "        \"new_coord\": params.parameters[\"poi_gage_id\"],\n",
    "        \"variables\": [\"seg_outflow\", \"seg_gwflow\"],#can add any other var with same coord here, eg. seg_gwflow/\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# A novel, diagnostic variable\n",
    "def sum_hru_flows(sroff_vol, ssres_flow_vol, gwres_flow_vol): #These vars used to calc, do not need to be in the var list\n",
    "    return sroff_vol + ssres_flow_vol + gwres_flow_vol\n",
    "\n",
    "\n",
    "diagnostic_var_dict = {\n",
    "    \"hru_streamflow_out\": {\n",
    "        \"inputs\": [\"sroff_vol\", \"ssres_flow_vol\", \"gwres_flow_vol\"],\n",
    "        \"function\": sum_hru_flows,\n",
    "        \"like_var\": \"sroff_vol\",\n",
    "        \"metadata\": {\"desc\": \"Total volume to stream network from each HRU\", \"units\": \"cubic feet\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "# TODO: specify subsets in time\n",
    "# TODO: specify different output files\n",
    "\n",
    "# /////////////////////////////////\n",
    "# code starts here\n",
    "\n",
    "out_subset_ds = xr.Dataset()\n",
    "\n",
    "needed_vars = var_list + [\n",
    "    var for key, val in diagnostic_var_dict.items() for var in val[\"inputs\"]\n",
    "]\n",
    "needed_metadata = pws.meta.get_vars(needed_vars)\n",
    "dims = set([dim for val in needed_metadata.values() for dim in val[\"dims\"]])\n",
    "\n",
    "subset_vars = [\n",
    "    var for key, val in spatial_subsets.items() for var in val[\"variables\"]\n",
    "]\n",
    "\n",
    "var_subset_key = {\n",
    "    var: subkey\n",
    "    for var in subset_vars\n",
    "    for subkey in spatial_subsets.keys()\n",
    "    if var in spatial_subsets[subkey][\"variables\"]\n",
    "}\n",
    "\n",
    "diagnostic_vars = list(diagnostic_var_dict.keys())\n",
    "\n",
    "# solve the processes for each variable\n",
    "var_proc = {\n",
    "    var: proc_key\n",
    "    for var in needed_vars\n",
    "    for proc_key, proc_val in model.processes.items()\n",
    "    if var in proc_val.get_variables()\n",
    "}\n",
    "\n",
    "time_coord = np.arange(control.start_time, control.end_time + control.time_step, dtype=\"datetime64[D]\"\n",
    "                      )\n",
    "n_time_steps = len(time_coord)\n",
    "out_subset_ds[\"time\"] = xr.Variable([\"time\"], time_coord)\n",
    "out_subset_ds = out_subset_ds.set_coords(\"time\")\n",
    "\n",
    "# annoying to have to hard-code this\n",
    "dim_coord = {\"nhru\": \"nhm_id\", \"nsegment\": \"nhm_seg\"}\n",
    "\n",
    "####################################################################################\n",
    "# declare memory for the outputs\n",
    "for var in var_list + diagnostic_vars:\n",
    "    # impostor approach\n",
    "    orig_diag_var = None\n",
    "    if var in diagnostic_vars:\n",
    "        orig_diag_var = var\n",
    "        var = diagnostic_var_dict[var][\"like_var\"]\n",
    "\n",
    "    proc = model.processes[var_proc[var]]\n",
    "    dim_name = needed_metadata[var][\"dims\"][0]\n",
    "    dim_len = proc.params.dims[dim_name]\n",
    "    coord_name = dim_coord[dim_name]\n",
    "    coord_data = proc.params.coords[dim_coord[dim_name]]\n",
    "    type = needed_metadata[var][\"type\"]\n",
    "\n",
    "    var_meta = {\n",
    "        kk: vv\n",
    "        for kk, vv in needed_metadata[var].items()\n",
    "        if kk in [\"desc\", \"units\"]\n",
    "    }\n",
    "\n",
    "    if orig_diag_var is not None:\n",
    "        var = orig_diag_var\n",
    "        del var_meta[\"desc\"]\n",
    "        if \"metadata\" in diagnostic_var_dict[var]:\n",
    "            var_meta = diagnostic_var_dict[var][\"metadata\"]\n",
    "        if \"desc\" not in var_meta.keys():\n",
    "            var_meta[\"desc\"] = \"Custom output diagnostic variable\"\n",
    "\n",
    "    if var in subset_vars:\n",
    "        subset_key = var_subset_key[var]\n",
    "        subset_info = spatial_subsets[subset_key]\n",
    "        dim_name = f\"n{subset_key}\"\n",
    "        coord_name = subset_key\n",
    "        dim_len = len(subset_info[\"indices\"][0])\n",
    "        coord_data = subset_info[\"new_coord\"]\n",
    "\n",
    "    if coord_name not in list(out_subset_ds.variables):\n",
    "        out_subset_ds[coord_name] = xr.DataArray(coord_data, dims=[dim_name])\n",
    "        out_subset_ds = out_subset_ds.set_coords(coord_name)\n",
    "\n",
    "    out_subset_ds[var] = xr.Variable(\n",
    "        [\"time\", dim_name],\n",
    "        np.full(\n",
    "            [n_time_steps, dim_len],\n",
    "            pws.constants.fill_values_dict[np.dtype(type)],\n",
    "            type,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    out_subset_ds[var].attrs = var_meta\n",
    "\n",
    "#########################################################################################\n",
    "#Is this the model running???? YES\n",
    "for istep in range(n_time_steps):\n",
    "    model.advance()\n",
    "    model.calculate()\n",
    "\n",
    "    if model_output_netcdf:\n",
    "        model.output()\n",
    "\n",
    "    for var in var_list:\n",
    "        proc = model.processes[var_proc[var]]\n",
    "        data = proc[var]\n",
    "        if isinstance(proc[var], pws.base.timeseries.TimeseriesArray):\n",
    "            data = data.current\n",
    "        if var not in subset_vars:\n",
    "            out_subset_ds[var][istep, :] = data\n",
    "        else:\n",
    "            indices = spatial_subsets[var_subset_key[var]][\"indices\"]\n",
    "            out_subset_ds[var][istep, :] = data[indices]\n",
    "\n",
    "    for diag_key, diag_val in diagnostic_var_dict.items():\n",
    "        input_dict = {}\n",
    "        for ii in diag_val[\"inputs\"]:\n",
    "            proc = model.processes[var_proc[ii]]\n",
    "            input_dict[ii] = proc[ii]\n",
    "\n",
    "        out_subset_ds[diag_key][istep, :] = diag_val[\"function\"](**input_dict)#this is where the diag_var is actually being calc'd/time step\n",
    "\n",
    "\n",
    "out_subset_ds.to_netcdf(custom_output_file)\n",
    "out_subset_ds.close()\n",
    "print(f\"Model run finished! That took {time.time()-sttime:.3f} looong seconds\")\n",
    "\n",
    "del proc\n",
    "del input_dict\n",
    "del model\n",
    "del out_subset_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747051a-f61f-479c-9a1f-868e6e7085ff",
   "metadata": {},
   "source": [
    "### Diagnostic Check\n",
    "#### Checks the custom output against the standard outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f7809-d252-416c-9ff1-0e73392ab04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_output_netcdf:\n",
    "    out_subset_ds = xr.open_dataset(custom_output_file)\n",
    "\n",
    "    for vv in var_list:\n",
    "        default_output_file = out_dir / f\"{vv}.nc\"\n",
    "        print(\"checking variable: \", vv)\n",
    "        answer = xr.load_dataarray(default_output_file)\n",
    "        \n",
    "        result = out_subset_ds[vv]\n",
    "\n",
    "        if vv in subset_vars:\n",
    "            indices = spatial_subsets[var_subset_key[vv]][\"indices\"]\n",
    "            answer = answer[:, indices[0]]\n",
    "\n",
    "        np.testing.assert_allclose(answer, result)\n",
    "        answer.close()\n",
    "\n",
    "    for diag_key, diag_val in diagnostic_var_dict.items():\n",
    "        print(\"checking diagnostic variable: \", diag_key)\n",
    "        input_dict = {}\n",
    "        for ii in diag_val[\"inputs\"]:\n",
    "            default_output_file = out_dir / f\"{ii}.nc\"\n",
    "            input_dict[ii] = xr.load_dataarray(default_output_file)\n",
    "\n",
    "        answer = diag_val[\"function\"](**input_dict)\n",
    "        result = out_subset_ds[diag_key]\n",
    "\n",
    "        np.testing.assert_allclose(answer, result)\n",
    "        \n",
    "    out_subset_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4532f49-5d04-4ecf-913c-cc88ad8cde34",
   "metadata": {},
   "source": [
    "#### Reading the custom output.nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cf15b-a49a-4626-8d7a-25c950a0220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output  = xr.load_dataset(out_dir / 'model_custom_output.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c121dc-6b86-4a51-ace4-95afdf0fb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ab5cc-9c3a-4448-a4a4-932c51da0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output.snowmelt.values[100,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf591a-cd05-47bd-a2fa-742939dc5ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dc595-28f0-4d1a-adde-659570fc0a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
