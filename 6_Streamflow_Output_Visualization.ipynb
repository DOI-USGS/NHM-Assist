{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"0a_Workspace_setup.ipynb\"\n",
    "\n",
    "from NHM_helpers.NHM_helpers import (\n",
    "    hrus_by_poi,\n",
    "    hrus_by_seg,\n",
    "    subset_stream_network,\n",
    "    create_poi_group,\n",
    ")\n",
    "from NHM_helpers.map_template import *\n",
    "from NHM_helpers.NHM_Assist_utilities import make_plots_par_vals\n",
    "\n",
    "from NHM_helpers.NHM_output_visualization import (\n",
    "    retrieve_hru_output_info,\n",
    "    create_sum_var_dataarrays,\n",
    "    create_mean_var_dataarrays,\n",
    "    create_sum_var_annual_gdf,\n",
    "    create_sum_var_annual_df,\n",
    "    create_sum_var_monthly_df,\n",
    "    create_var_daily_df,\n",
    "    create_var_ts_for_poi_basin_df,\n",
    ")\n",
    "from NHM_helpers.output_plots import *\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "poi_id_sel = None\n",
    "\n",
    "crs = 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mplib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import folium\n",
    "from folium import Choropleth, Circle, Marker\n",
    "\n",
    "from folium import plugins\n",
    "from shapely.geometry import Polygon\n",
    "from folium.features import DivIcon\n",
    "from folium.plugins import MarkerCluster\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "\n",
    "from tobler.dasymetric import masked_area_interpolate\n",
    "from tobler.model import glm\n",
    "from tobler.area_weighted import area_interpolate\n",
    "\n",
    "from libpysal.examples import load_example\n",
    "\n",
    "import hydroeval as he\n",
    "\n",
    "# import hyswap\n",
    "# from hyswap.percentiles import calculate_variable_percentile_thresholds_by_day\n",
    "# from hyswap.cumulative import calculate_daily_cumulative_values\n",
    "import calendar\n",
    "import statistics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subset_stream_network(dag_ds, uscutoff_seg, dsmost_seg):\n",
    "#     \"\"\"Extract subset of stream network\n",
    "\n",
    "#     :param dag_ds: Directed, acyclic graph of downstream stream network\n",
    "#     :param uscutoff_seg: List of upstream cutoff segments\n",
    "#     :param dsmost_seg: List of outlet segments to start extraction from\n",
    "\n",
    "#     :returns: Stream network of extracted segments\n",
    "#     \"\"\"\n",
    "\n",
    "#     # taken from Bandit bandit_helpers.py\n",
    "\n",
    "#     # Create the upstream graph\n",
    "#     dag_us = dag_ds.reverse()\n",
    "\n",
    "#     # Trim the u/s graph to remove segments above the u/s cutoff segments\n",
    "#     try:\n",
    "#         for xx in uscutoff_seg:\n",
    "#             try:\n",
    "#                 dag_us.remove_nodes_from(nx.dfs_predecessors(dag_us, xx))\n",
    "\n",
    "#                 # Also remove the cutoff segment itself\n",
    "#                 dag_us.remove_node(xx)\n",
    "#             except KeyError:\n",
    "#                 print(f\"WARNING: nhm_segment {xx} does not exist in stream network\")\n",
    "#     except TypeError:\n",
    "#         print(\n",
    "#             \"\\nSelected cutoffs should at least be an empty list instead of NoneType.\"\n",
    "#         )\n",
    "\n",
    "#     # =======================================\n",
    "#     # Given a d/s segment (dsmost_seg) create a subset of u/s segments\n",
    "\n",
    "#     # Get all unique segments u/s of the starting segment\n",
    "#     uniq_seg_us: Set[int] = set()\n",
    "#     if dsmost_seg:\n",
    "#         for xx in dsmost_seg:\n",
    "#             try:\n",
    "#                 pred = nx.dfs_predecessors(dag_us, xx)\n",
    "#                 uniq_seg_us = uniq_seg_us.union(\n",
    "#                     set(pred.keys()).union(set(pred.values()))\n",
    "#                 )\n",
    "#             except KeyError:\n",
    "#                 print(f\"KeyError: Segment {xx} does not exist in stream network\")\n",
    "\n",
    "#         # Get a subgraph in the dag_ds graph and return the edges\n",
    "#         dag_ds_subset = dag_ds.subgraph(uniq_seg_us).copy()\n",
    "\n",
    "#         node_outlets = [ee[0] for ee in dag_ds_subset.edges()]\n",
    "#         true_outlets = set(dsmost_seg).difference(set(node_outlets))\n",
    "\n",
    "#         # Add the downstream segments that exit the subgraph\n",
    "#         for xx in true_outlets:\n",
    "#             nhm_outlet = list(dag_ds.neighbors(xx))[0]\n",
    "#             dag_ds_subset.add_node(\n",
    "#                 nhm_outlet, style=\"filled\", fontcolor=\"white\", fillcolor=\"grey\"\n",
    "#             )\n",
    "#             dag_ds_subset.add_edge(xx, nhm_outlet)\n",
    "#             dag_ds_subset.nodes[xx][\"style\"] = \"filled\"\n",
    "#             dag_ds_subset.nodes[xx][\"fontcolor\"] = \"white\"\n",
    "#             dag_ds_subset.nodes[xx][\"fillcolor\"] = \"blue\"\n",
    "#     else:\n",
    "#         # No outlets specified so pull the full model\n",
    "#         dag_ds_subset = dag_ds\n",
    "\n",
    "#     return dag_ds_subset\n",
    "\n",
    "\n",
    "# def hrus_by_seg(pdb, segs):\n",
    "#     # segs: global segment IDs\n",
    "\n",
    "#     if isinstance(segs, int):\n",
    "#         segs = [segs]\n",
    "#     elif isinstance(segs, KeysView):\n",
    "#         segs = list(segs)\n",
    "\n",
    "#     seg_hrus = {}\n",
    "#     seg_to_hru = pdb.seg_to_hru\n",
    "\n",
    "#     # Generate stream network for the model\n",
    "#     dag_streamnet = pdb.stream_network()\n",
    "\n",
    "#     for cseg in segs:\n",
    "#         # Lookup segment for the current POI\n",
    "#         dsmost_seg = [cseg]\n",
    "\n",
    "#         # Get subset of stream network for given POI\n",
    "#         dag_ds_subset = subset_stream_network(dag_streamnet, set(), dsmost_seg)\n",
    "\n",
    "#         # Create list of segments in the subset\n",
    "#         toseg_idx = list(set(xx[0] for xx in dag_ds_subset.edges))\n",
    "\n",
    "#         # Build list of HRUs that contribute to the POI\n",
    "#         final_hru_list = []\n",
    "\n",
    "#         for xx in toseg_idx:\n",
    "#             try:\n",
    "#                 for yy in seg_to_hru[xx]:\n",
    "#                     final_hru_list.append(yy)\n",
    "#             except KeyError:\n",
    "#                 # print(f'Segment {xx} has no HRUs connected to it') # comment this out and add pass to not print the KeyError\n",
    "#                 pass\n",
    "#         final_hru_list.sort()\n",
    "\n",
    "#         seg_hrus[cseg] = final_hru_list\n",
    "\n",
    "#     return seg_hrus\n",
    "\n",
    "\n",
    "# def hrus_by_poi(pdb, poi):\n",
    "#     if isinstance(poi, str):\n",
    "#         poi = [poi]\n",
    "#     elif isinstance(poi, KeysView):\n",
    "#         poi = list(poi)\n",
    "\n",
    "#     poi_hrus = {}\n",
    "#     nhm_seg = pdb.get(\"nhm_seg\").data\n",
    "#     pois_dict = pdb.poi_to_seg\n",
    "#     seg_to_hru = pdb.seg_to_hru\n",
    "\n",
    "#     # Generate stream network for the model\n",
    "#     dag_streamnet = pdb.stream_network()\n",
    "\n",
    "#     for cpoi in poi:\n",
    "#         # Lookup global segment id for the current POI\n",
    "#         dsmost_seg = [nhm_seg[pois_dict[cpoi] - 1]]\n",
    "\n",
    "#         # Get subset of stream network for given POI\n",
    "#         dag_ds_subset = subset_stream_network(dag_streamnet, set(), dsmost_seg)\n",
    "\n",
    "#         # Create list of segments in the subset\n",
    "#         toseg_idx = list(set(xx[0] for xx in dag_ds_subset.edges))\n",
    "\n",
    "#         # Build list of HRUs that contribute to the POI\n",
    "#         final_hru_list = []\n",
    "\n",
    "#         for xx in toseg_idx:\n",
    "#             try:\n",
    "#                 for yy in seg_to_hru[xx]:\n",
    "#                     final_hru_list.append(yy)\n",
    "#             except KeyError:\n",
    "#                 # Not all segments have HRUs connected to them\n",
    "#                 # print(f'{cpoi}: Segment {xx} has no HRUs connected to it')\n",
    "#                 pass\n",
    "#         final_hru_list.sort()\n",
    "#         poi_hrus[cpoi] = final_hru_list\n",
    "\n",
    "#     return poi_hrus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_table(stats_df):\n",
    "\n",
    "    evaluations = stats_df.discharge\n",
    "    std_evaluations = statistics.stdev(evaluations)\n",
    "\n",
    "    simulations = stats_df.seg_outflow\n",
    "\n",
    "    rmse = np.round(he.evaluator(he.rmse, simulations, evaluations), 2)\n",
    "    nse = np.round(he.evaluator(he.nse, simulations, evaluations), 2)\n",
    "    pbias = np.round(he.evaluator(he.pbias, simulations, evaluations), 2)\n",
    "    kge, r, alpha, beta = np.round(he.evaluator(he.kge, simulations, evaluations), 2)\n",
    "\n",
    "    rsr = np.round(rmse / std_evaluations, 2)\n",
    "    r_sq = np.round(np.array([r2_score(simulations, evaluations)]), 2)\n",
    "\n",
    "    stat_dict = {\n",
    "        \"KGE\": kge[0],\n",
    "        \"NSE\": nse[0],\n",
    "        \"Pbias\": pbias[0],\n",
    "        \"RMSE\": rmse[0],\n",
    "        \"R^2\": r_sq[0],\n",
    "        \"R\": r[0],\n",
    "        \"Alpha\": alpha[0],\n",
    "        \"Beta\": beta[0],\n",
    "        \"RSR\": rsr[0],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(stat_dict, index=[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for hydrofabric elements\n",
    "hru_gdf = create_hru_gdf(\n",
    "    NHM_dir,\n",
    "    model_dir,\n",
    "    GIS_format,\n",
    "    param_filename,\n",
    "    nhru_params,\n",
    "    nhru_nmonths_params,\n",
    ")\n",
    "\n",
    "seg_gdf = create_segment_gdf(\n",
    "    model_dir,\n",
    "    GIS_format,\n",
    "    param_filename,\n",
    ")\n",
    "\n",
    "nwis_gages_aoi = fetch_nwis_gage_info(\n",
    "    model_dir,\n",
    "    control_file_name,\n",
    "    nwis_gage_nobs_min,\n",
    "    hru_gdf,\n",
    ")\n",
    "\n",
    "poi_df = create_poi_df(\n",
    "    model_dir,\n",
    "    param_filename,\n",
    "    control_file_name,\n",
    "    hru_gdf,\n",
    "    nwis_gages_aoi,\n",
    "    gages_file,\n",
    ")\n",
    "\n",
    "default_gages_file = create_default_gages_file(\n",
    "    model_dir,\n",
    "    nwis_gages_aoi,\n",
    "    poi_df,\n",
    ")\n",
    "\n",
    "gages_df = read_gages_file(\n",
    "    model_dir,\n",
    "    poi_df,\n",
    "    nwis_gages_file,\n",
    "    gages_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NHM Calibration Levels for HRUs: (those hrus calibrated in byHW and byHWobs parts)\n",
    "HW basins were descritized using a drainage area maxiumum and minimum; HW HRUs, segments, outlet segment, and drainage area are available. Gages used in byHWobs calibration, Part 3, for selected headwaters are also provided here.  FILES AND TABLES IN THIS SECTION ARE CONUS COVERAGE and will be subsetted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### READ table (.csv) of HRU calibration level file\n",
    "# hru_cal_levels_df = pd.read_csv(\n",
    "#     r\"data_dependencies/NHM_v1_1/nhm_v1_1_HRU_cal_levels.csv\"\n",
    "# ).fillna(0)\n",
    "# hru_cal_levels_df[\"hw_id\"] = hru_cal_levels_df.hw_id.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hru_cal_levels_df = pd.merge(\n",
    "#     hru_cal_levels_df, hru_gdf, right_on=\"nhm_id\", left_on=\"nhm_id\"\n",
    "# )\n",
    "# hru_cal_levels_gdf = gpd.GeoDataFrame(\n",
    "#     hru_cal_levels_df, geometry=\"geometry\"\n",
    "# )  # Creates a Geopandas GeoDataFrame\n",
    "# hru_cal_levels_gdf[\"nhm_id\"] = hru_cal_levels_gdf[\"nhm_id\"].astype(str)\n",
    "# hru_cal_levels_gdf[\"hw_id\"] = hru_cal_levels_gdf[\"hw_id\"].astype(str)\n",
    "\n",
    "# print(\n",
    "#     \"The number of HRUs in the byHRU calibration is\",\n",
    "#     hru_cal_levels_gdf[hru_cal_levels_gdf[\"level\"] > 0][\"level\"].count(),\n",
    "# )\n",
    "# print(\n",
    "#     \"The number of HRUs in the byHW calibration is\",\n",
    "#     hru_cal_levels_gdf[hru_cal_levels_gdf[\"level\"] > 1][\"level\"].count(),\n",
    "# )\n",
    "# print(\n",
    "#     \"The number of HRUs in the byHWobs calibration is\",\n",
    "#     hru_cal_levels_gdf[hru_cal_levels_gdf[\"level\"] > 2][\"level\"].count(),\n",
    "# )\n",
    "\n",
    "\n",
    "# # hru_cal_levels_df #View results to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add headwater basin (NHM calibration basin) outline layer on the map for referrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_HW_cal_level_files(hru_gdf):\n",
    "    \"\"\" \"\"\"\n",
    "    byHW_basins_gdf = hru_gdf.loc[hru_gdf[\"byHW\"] == 1]\n",
    "    HW_basins_gdf = byHW_basins_gdf.dissolve(by=\"hw_id\").to_crs(crs)\n",
    "    HW_basins_gdf.reset_index(inplace=True, drop=False)\n",
    "    HW_basins = HW_basins_gdf.boundary\n",
    "\n",
    "    return HW_basins_gdf, HW_basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HW_basins_gdf, HW_basins = make_HW_cal_level_files(hru_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the NHM poi gages that were used in claibration byHWobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in the csv file that hase the gages used to calibrate the byHWobs part for CONUS.\n",
    "# Read in station file columns needed (You may need to tailor this to the particular file.\n",
    "col_names = [\n",
    "    \"poi_id\",\n",
    "    #'poi_name',\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    #'drainage_area',\n",
    "    #'drainage_area_contrib'\n",
    "]\n",
    "col_types = [\n",
    "    np.str_,\n",
    "    # np.str_,\n",
    "    float,\n",
    "    float,\n",
    "    # float,\n",
    "    # float\n",
    "]\n",
    "cols = dict(\n",
    "    zip(col_names, col_types)\n",
    ")  # Creates a dictionary of column header and datatype called below.\n",
    "\n",
    "byHWobs_poi_df = pd.read_csv(\n",
    "    r\"data_dependencies/NHM_v1_1/nhm_v1_1_byhwobs_cal_gages.csv\", sep=\"\\t\", dtype=cols\n",
    ").fillna(0)\n",
    "\n",
    "# byHWobs_poi_df = pd.read_csv(f'{NHM_dir}/nhm_v11_hwobs_pois.csv', sep='\\t').fillna(0)\n",
    "# byHWobs_poi_df['poi_id'] = byHWobs_poi_df.poi_id.astype('str') # makes sure that this is a string,\n",
    "# must have the leading zeros; suggest a more formal read and set like used in prev notebook.\n",
    "\n",
    "# Identify the byHWobs calibration gages in our current poi database (ammended in the model prams file to include more gages)\n",
    "poi_df[\"nhm_calib\"] = \"N\"\n",
    "poi_df.loc[poi_df[\"poi_id\"].isin(byHWobs_poi_df[\"poi_id\"]), \"nhm_calib\"] = \"Y\"\n",
    "# poi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.poi_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve pywatershed output file information.\n",
    "> explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start_date, plot_end_date, year_list, output_var_list = retrieve_hru_output_info(\n",
    "    out_dir,\n",
    "    water_years,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute KGE for all gages to color the icon on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set WY start and stop times, and output variable needed for slicing the time series data for plotting\n",
    "# WY_start = \"1979-10-01\"\n",
    "# WY_end = \"2021-09-30\"\n",
    "# # Note that the model start and stop times in the control file should be the same as the observation start and stop times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in simulated flows and write daily ts array and for resample: monthly and annual\n",
    "output_var_sel = \"seg_outflow\"\n",
    "with xr.load_dataarray(out_dir / f\"{output_var_sel}.nc\") as da:\n",
    "    # these machinations are to keep downstream things as they were before some refactoring\n",
    "    # da = da.to_dataset().rename_dims({\"nhm_seg\": \"nhru\"})[da.name]\n",
    "    sf_units = da.units\n",
    "    da = da.swap_dims(nhm_seg=\"npoi_gages\")\n",
    "    output_var = da\n",
    "    output_var_daily = da.sel(time=slice(plot_start_date, plot_end_date))\n",
    "    output_var_monthly = output_var_daily.resample(time=\"m\").sum()\n",
    "    # Water year annual\n",
    "    output_var_annual = output_var_daily.resample(time=\"A-SEP\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in observed flows\n",
    "# Note that the model start and stop times in the control file should be the same as the observation start and stop times.\n",
    "sf_filename = model_dir / \"notebook_output_files\" / \"nc_files\" / \"sf_efc.nc\"\n",
    "\n",
    "with xr.open_dataset(sf_filename) as obs_data:\n",
    "    # Make a station name dataframe and station id list from the streamflow file .nc (created in previous notebook)\n",
    "    # station_name_df = getattr(\n",
    "    #     obs_data, \"poi_name\"\n",
    "    # ).to_dataframe()  # supporting df for plot labeling\n",
    "    station_name_df = obs_data[\"poi_name\"].to_dataframe()\n",
    "    station_id_list = station_name_df.index.to_list()  # supporting list for processing\n",
    "\n",
    "    # Resample daily timeseries arrays: monthly and annual\n",
    "    obs_0 = obs_data.sel(\n",
    "        time=slice(plot_start_date, plot_end_date)\n",
    "    ).transpose()  # load_dataset will open, read into memory and close the .nc file\n",
    "    obs_efc = obs_0[\"efc\"]  # getattr(obs_0, \"efc\")\n",
    "    obs = obs_0[\"discharge\"]  # getattr(obs_0, \"discharge\")\n",
    "    obs_monthly = obs.resample(time=\"m\").mean()\n",
    "    obs_annual = obs.resample(time=\"A-SEP\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_var_monthly\n",
    "# obs_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, row in poi_df.iterrows():\n",
    "#     zzz= output_var_monthly.sel(npoi_gages = row['poi_id']).values.tolist()\n",
    "#     kkk= obs_monthly.sel(poi_id = row['poi_id']).values.tolist()\n",
    "#     #print(len(zzz), len(kkk))\n",
    "#     print(zzz[0], kkk[0])\n",
    "\n",
    "test = poi_df.poi_id[0]\n",
    "zzz = output_var_monthly.sel(npoi_gages=test).values.tolist()\n",
    "kkk = obs_monthly.sel(poi_id=test).values.tolist()\n",
    "# print(len(zzz), len(kkk))\n",
    "# print(zzz, kkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df[\"kge\"] = np.nan\n",
    "for idx, row in poi_df.iterrows():\n",
    "    poi_id_sel = row[\"poi_id\"]\n",
    "    df_sf_data_sel = (obs.sel(poi_id=poi_id_sel)).to_dataframe()\n",
    "\n",
    "    # Determine por\n",
    "    por_start = df_sf_data_sel[\"discharge\"].notna().idxmax()  # First Day\n",
    "    por_end = df_sf_data_sel[\"discharge\"].notna()[::-1].idxmax()  # Last Day\n",
    "\n",
    "    # Slice to por\n",
    "    df_sf_data_sel = (\n",
    "        obs.sel(poi_id=poi_id_sel, time=slice(por_start, por_end))\n",
    "    ).to_dataframe()\n",
    "    df_sf_data_sel.drop(columns=[\"poi_id\"], inplace=True)  # drop unwanted columns\n",
    "\n",
    "    sim_flow = (\n",
    "        output_var.sel(npoi_gages=poi_id_sel, time=slice(por_start, por_end))\n",
    "    ).to_dataframe()\n",
    "    sim_flow.drop(columns=[\"npoi_gages\"], inplace=True)  # drop unwanted columns\n",
    "\n",
    "    # drop the Nan's from the obs for memory/stats (may want to check back on this later)\n",
    "    daily_stat_df = (\n",
    "        df_sf_data_sel.merge(sim_flow, right_index=True, left_index=True, how=\"inner\")\n",
    "    ).dropna()\n",
    "    month_stat_df = daily_stat_df.resample(\"m\").mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_stat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate kge and add value to poi_df\n",
    "poi_df[\"kge\"] = np.nan\n",
    "for idx, row in poi_df.iterrows():\n",
    "    poi_id_sel = row[\"poi_id\"]\n",
    "    df_sf_data_sel = (obs.sel(poi_id=poi_id_sel)).to_dataframe()\n",
    "\n",
    "    # Determine por\n",
    "    por_start = df_sf_data_sel[\"discharge\"].notna().idxmax()  # First Day\n",
    "    por_end = df_sf_data_sel[\"discharge\"].notna()[::-1].idxmax()  # Last Day\n",
    "\n",
    "    # Slice to por\n",
    "    df_sf_data_sel = (\n",
    "        obs.sel(poi_id=poi_id_sel, time=slice(por_start, por_end))\n",
    "    ).to_dataframe()\n",
    "    df_sf_data_sel.drop(columns=[\"poi_id\"], inplace=True)  # drop unwanted columns\n",
    "\n",
    "    sim_flow = (\n",
    "        output_var.sel(npoi_gages=poi_id_sel, time=slice(por_start, por_end))\n",
    "    ).to_dataframe()\n",
    "    sim_flow.drop(columns=[\"npoi_gages\"], inplace=True)  # drop unwanted columns\n",
    "\n",
    "    # drop the Nan's from the obs for memory/stats (may want to check back on this later)\n",
    "    daily_stat_df = (\n",
    "        df_sf_data_sel.merge(sim_flow, right_index=True, left_index=True, how=\"inner\")\n",
    "    ).dropna()\n",
    "    month_stat_df = daily_stat_df.resample(\"m\").mean().dropna()\n",
    "\n",
    "    # kge_func  = np.round(he.evaluator(he.kge,\n",
    "    #                                   daily_stat_df['seg_outflow'],# simulation data set\n",
    "    #                                   daily_stat_df['discharge'],# observation data set\n",
    "    #                                  ), 2# decimal places for the round() function\n",
    "    #                     )[0]#this grabs only the kge var, in position\"0\" from the list of ke.kge() output vars\n",
    "\n",
    "    # poi_df.loc[idx, 'kge'] = np.array(kge_func[0])# pandas wrangling of the array output from he.evaluator() as an array\n",
    "\n",
    "    kge_func = np.round(\n",
    "        he.evaluator(\n",
    "            he.kge,\n",
    "            month_stat_df[\"seg_outflow\"],  # simulation data set\n",
    "            month_stat_df[\"discharge\"],  # observation data set\n",
    "        ),\n",
    "        2,  # decimal places for the round() function\n",
    "    )[\n",
    "        0\n",
    "    ]  # this grabs only the kge var, in position\"0\" from the list of ke.kge() output vars\n",
    "\n",
    "    poi_df.loc[idx, \"kge\"] = np.array(\n",
    "        kge_func[0]\n",
    "    )  # pandas wrangling of the array output from he.evaluator() as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.kge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interactive map to evaluate streamflow at poi_gages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read mapping elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile_lat, pfile_lon, zoom, cluster_zoom = folium_map_elements(\n",
    "    hru_gdf, poi_df, poi_id_sel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USGSHydroCached_layer, USGStopo_layer, Esri_WorldImagery, OpenTopoMap = (\n",
    "    folium_map_tiles()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimap = create_minimap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi_id_sel = None\n",
    "# # Set map CRS, center, zoom, basemaps, and inset\n",
    "\n",
    "# crs = 4326\n",
    "\n",
    "# # pfile lat, lon derived for starting point of folium plot windows. Zoom also set here.\n",
    "# hru_gdf_map = hru_gdf.to_crs(crs)\n",
    "# lat = hru_gdf_map[\"hru_lat\"].mean()\n",
    "# lon = hru_gdf_map[\"hru_lon\"].mean() - 1\n",
    "# zoom = 7\n",
    "\n",
    "# # Set base map options\n",
    "# USGStopo_layer = folium.TileLayer(\n",
    "#     tiles=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSTopo/MapServer/tile/{z}/{y}/{x}\",\n",
    "#     attr=\"USGS_topo\",\n",
    "#     zoom_start=zoom,\n",
    "#     name=\"USGSTopo\",\n",
    "# )\n",
    "# USGSHydroCached_layer = folium.TileLayer(\n",
    "#     tiles=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSHydroCached/MapServer/tile/{z}/{y}/{x}\",\n",
    "#     attr=\"USGSHydroCached\",\n",
    "#     zoom_start=zoom,\n",
    "#     name=\"USGSHydroCached\",\n",
    "# )\n",
    "\n",
    "# # Format the inset map\n",
    "# minimap = plugins.MiniMap(\n",
    "#     tile_layer=\"OpenStreetMap\",\n",
    "#     # attr = 'USGS_topo',\n",
    "#     position=\"topleft\",\n",
    "#     # zoom_level_offset=- 4,\n",
    "#     height=200,\n",
    "#     width=200,\n",
    "#     collapsed_height=25,\n",
    "#     collapsed_width=25,\n",
    "#     zoom_level_fixed=5,\n",
    "#     toggle_display=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set style functions for map\n",
    "# style_function_hru_map = lambda x: {\n",
    "#     \"opacity\": 1,\n",
    "#     \"fillColor\": \"#00000000\",  #'goldenrod',\n",
    "#     \"color\": \"tan\",\n",
    "#     \"weight\": 1.5,\n",
    "# }\n",
    "# highlight_function_hru_map = lambda x: {\n",
    "#     \"opacity\": 0.5,\n",
    "#     \"color\": \"gray\",\n",
    "#     \"fillColor\": \"gray\",\n",
    "#     \"weight\": 3,\n",
    "# }\n",
    "# style_function_seg_map = lambda x: {\"opacity\": 1, \"color\": \"#217de7\", \"weight\": 2}\n",
    "# highlight_function_seg_map = lambda x: {\"opacity\": 1, \"color\": \"lightblue\", \"weight\": 4}\n",
    "# transparent = lambda x: {\n",
    "#     \"fillColor\": \"#00000000\",\n",
    "#     \"color\": \"#00000000\",\n",
    "#     \"weight\": 4,\n",
    "# }\n",
    "\n",
    "# cp_style_function = lambda feature: {\n",
    "#     \"fillColor\": linear(var_sel_color_dict[feature[\"id\"]]),\n",
    "#     \"color\": \"tan\",\n",
    "#     \"weight\": 1,\n",
    "#     # \"dashArray\": \"5, 5\",\n",
    "#     \"fillOpacity\": 0.3,\n",
    "# }\n",
    "# hw_basin_style = lambda x: {\n",
    "#     \"fillColor\": \"#00000000\",\n",
    "#     #'fill_opacity' : .8,\n",
    "#     \"color\": \"white\",\n",
    "#     \"weight\": 2,\n",
    "#     # \"dashArray\": \"5, 5\",\n",
    "# }\n",
    "# cal_style_function = lambda feature: {\n",
    "#     \"fillColor\": (\n",
    "#         \"gray\"\n",
    "#         if feature[\"properties\"][\"level\"] == 1\n",
    "#         else \"yellow\" if feature[\"properties\"][\"level\"] == 2 else \"green\"\n",
    "#     ),\n",
    "#     \"color\": \"#00000000\",\n",
    "#     \"weight\": 1.5,\n",
    "#     # \"dashArray\": \"5, 5\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from folium.plugins import MeasureControl\n",
    "from folium.utilities import Element\n",
    "from folium.plugins import FloatImage\n",
    "import base64\n",
    "\n",
    "# Set map\n",
    "# if poi_id_sel:\n",
    "#     poi_lookup = poi_id_sel\n",
    "#     lat = poi_df.loc[poi_df.poi_id == poi_lookup, \"latitude\"].values[0]\n",
    "#     lon = poi_df.loc[poi_df.poi_id == poi_lookup, \"longitude\"].values[0]\n",
    "#     zoom = 12\n",
    "#     poi_id_sel = None\n",
    "# else:\n",
    "#     lat = hru_gdf_map[\"hru_lat\"].mean()\n",
    "#     lon = hru_gdf_map[\"hru_lon\"].mean() - 1\n",
    "#     zoom = 7\n",
    "\n",
    "# Load standard map settings\n",
    "pfile_lat, pfile_lon, zoom, cluster_zoom = folium_map_elements(\n",
    "    hru_gdf, poi_df, poi_id_sel\n",
    ")\n",
    "\n",
    "# Clear map if previously created\n",
    "m = folium.Map()\n",
    "\n",
    "# Create map\n",
    "m = folium.Map(\n",
    "    location=[pfile_lat, pfile_lon],\n",
    "    # width=1000, height=600,\n",
    "    tiles=USGSHydroCached_layer,\n",
    "    zoom_start=zoom,\n",
    "    control_scale=True,\n",
    ")\n",
    "\n",
    "# Add base map layers\n",
    "USGStopo_layer.add_to(m)\n",
    "OpenTopoMap.add_to(m)\n",
    "Esri_WorldImagery.add_to(m)\n",
    "\n",
    "# Add widgets\n",
    "m.add_child(minimap)\n",
    "m.add_child(MeasureControl(position=\"bottomright\"))\n",
    "\n",
    "\n",
    "# m = folium.Map()\n",
    "\n",
    "# m = folium.Map(\n",
    "#     location=[lat, lon],\n",
    "#     # width=800, height=600,\n",
    "#     tiles=USGSHydroCached_layer,\n",
    "#     zoom_start=zoom,\n",
    "# )\n",
    "# folium.TileLayer(\n",
    "#     tiles=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSTopo/MapServer/tile/{z}/{y}/{x}\",\n",
    "#     attr=\"USGS_Topo\",\n",
    "#     zoom_start=zoom,\n",
    "#     name=\"USGS Topography\",\n",
    "#     show=False,\n",
    "# ).add_to(m)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Create and add hru map\n",
    "# hru_gdf_map = HW_basins_gdf.to_crs(crs)\n",
    "hru_map = folium.GeoJson(\n",
    "    HW_basins_gdf,  # hru_gdf_map,\n",
    "    style_function=cal_style_function,\n",
    "    # highlight_function = highlight_function_hru_map,\n",
    "    name=\"NHM HRUs\",\n",
    "    z_index_offset=40002,\n",
    ").add_to(m)\n",
    "\n",
    "tooltip_hru = folium.GeoJsonPopup(\n",
    "    fields=[\"hw_id\"], aliases=[\"Headwater id\"], labels=True\n",
    ")\n",
    "\n",
    "# Add tool tip to map\n",
    "hru_map.add_child(tooltip_hru)\n",
    "\n",
    "################################################\n",
    "# Create and add segments map\n",
    "# seg_gdf_map = seg_gdf.to_crs(crs)\n",
    "# seg_map = folium.GeoJson(\n",
    "#     seg_gdf_map,\n",
    "#     style_function=style_function_seg_map,\n",
    "#     highlight_function=highlight_function_seg_map,  # lambda feature: {\"fillcolor\": \"white\", \"color\": \"white\"},\n",
    "#     name=\"NHM Segments\",\n",
    "#     control=True,\n",
    "#     z_index_offset=40003,\n",
    "# ).add_to(m)\n",
    "\n",
    "# tooltip_seg = folium.GeoJsonTooltip(\n",
    "#     fields=[\"nhm_seg\", \"tosegment_nhm\"],\n",
    "#     aliases=[\"Segment\", \"flows to segment\"],\n",
    "#     labels=True,\n",
    "# )\n",
    "# seg_map.add_child(tooltip_seg)\n",
    "\n",
    "# Create/Add segment map\n",
    "seg_map = create_segment_map_hide(seg_gdf)\n",
    "seg_map.add_to(m)\n",
    "\n",
    "################################################\n",
    "# add POI marker clusters (marker and label)\n",
    "# byHRU_Group = folium.FeatureGroup(name='HRUs calibrated by HRU -- brown')\n",
    "marker_cluster = folium.FeatureGroup(\n",
    "    name=\"All the POIs\",\n",
    "    overlay=True,\n",
    "    control=True,\n",
    "    icon_create_function=None,\n",
    "    z_index_offset=5000,\n",
    ")\n",
    "marker_cluster_label_poi = folium.FeatureGroup(\n",
    "    name=\"All the POI labels\",\n",
    "    overlay=True,\n",
    "    control=True,\n",
    "    show=False,  # False will not draw the child upon opening the map, but have it to draw in the Layer control.\n",
    "    icon_create_function=None,\n",
    "    z_index_offset=4004,\n",
    ")\n",
    "\n",
    "\n",
    "################################################\n",
    "# Add the inset map\n",
    "m.add_child(minimap)\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "# Make Administrative basin labels\n",
    "label_coord_x = 20\n",
    "label_coor_y = 10\n",
    "\n",
    "\n",
    "for idx, row in poi_df.iterrows():\n",
    "    poi_id = row[\"poi_id\"]\n",
    "    var_plot_file = Folium_maps_dir / f\"{output_var_sel}_{poi_id}.txt\"\n",
    "\n",
    "    if row[\"nhm_calib\"] == \"Y\":  # Do this for all the gages used in calibration\n",
    "        if row[\"kge\"] >= 0.7:\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br>',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=5,\n",
    "                weight=2,\n",
    "                color=\"Black\",\n",
    "                fill=True,\n",
    "                fill_color=\"Green\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "        if (row[\"kge\"] < 0.7) & (row[\"kge\"] >= 0.5):\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br>',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=5,\n",
    "                weight=2,\n",
    "                color=\"Black\",\n",
    "                fill=True,\n",
    "                fill_color=\"Yellow\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            # marker_cluster.add_child(marker)\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "        if row[\"kge\"] < 0.5:\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br>',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=5,\n",
    "                weight=2,\n",
    "                color=\"Black\",\n",
    "                fill=True,\n",
    "                fill_color=\"Red\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            # marker_cluster.add_child(marker)\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "    ################################################\n",
    "\n",
    "    ###########\n",
    "    if row[\"nhm_calib\"] == \"N\":\n",
    "        if row[\"kge\"] >= 0.7:\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br>',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=5,\n",
    "                weight=2,\n",
    "                color=None,\n",
    "                fill=True,\n",
    "                fill_color=\"Green\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            # marker_cluster.add_child(marker)\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "        if (row[\"kge\"] < 0.7) & (row[\"kge\"] >= 0.5):\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br>',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=5,\n",
    "                weight=2,\n",
    "                color=None,\n",
    "                fill=True,\n",
    "                fill_color=\"Yellow\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            # marker_cluster.add_child(marker)\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "        if row[\"kge\"] < 0.5:\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br>',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=5,\n",
    "                weight=2,\n",
    "                color=None,\n",
    "                fill=True,\n",
    "                fill_color=\"Red\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            # marker_cluster.add_child(marker)\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "        if np.isnan(row[\"kge\"]):\n",
    "\n",
    "            marker = folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                name=row[\"poi_id\"],\n",
    "                popup=folium.Popup(\n",
    "                    f'Gage <b>{row[\"poi_id\"]}</b>, {row[\"poi_name\"]}<br> Gage has less than 2yrs of observations.',\n",
    "                    max_width=150,\n",
    "                    max_height=70,\n",
    "                ),\n",
    "                radius=2,\n",
    "                weight=2,\n",
    "                color=\"Black\",\n",
    "                fill=True,\n",
    "                fill_color=\"Black\",\n",
    "                fill_opacity=1.0,\n",
    "                draggable=True,\n",
    "                lazy=True,\n",
    "                z_index_offset=4006,\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "            # marker_cluster.add_child(marker)\n",
    "            text = f'{row[\"poi_id\"]}'\n",
    "            label_lat = row[\"latitude\"]  # -0.005\n",
    "            label_lon = row[\"longitude\"]\n",
    "\n",
    "            marker_label = folium.map.Marker(\n",
    "                [label_lat, label_lon],\n",
    "                z_index_offset=4007,\n",
    "                icon=DivIcon(\n",
    "                    icon_size=(150, 36),\n",
    "                    icon_anchor=(0, 0),\n",
    "                    html='<div style=\"font-size: 12pt; font-weight: bold\">%s</div>'\n",
    "                    % text,\n",
    "                ),\n",
    "            ).add_to(marker_cluster_label_poi)\n",
    "    # ################################################\n",
    "# Add hw boundary ref map\n",
    "hw_basins_map = folium.GeoJson(\n",
    "    HW_basins, style_function=hw_basin_style, name=\"HW basin boundary\"\n",
    ").add_to(m)\n",
    "\n",
    "################################################\n",
    "marker_cluster.add_to(m)\n",
    "marker_cluster_label_poi.add_to(m)\n",
    "\n",
    "plugins.Fullscreen(position=\"topleft\").add_to(m)\n",
    "folium.LayerControl(collapsed=True, position=\"bottomright\", autoZIndex=True).add_to(m)\n",
    "\n",
    "################################################\n",
    "# Print map header\n",
    "con.print(f\"\")\n",
    "con.print(f\"\")\n",
    "con.print(f\"\")\n",
    "con.print(\"NHM poi_gages map\", style=\"u bold black\")\n",
    "con.print(\n",
    "    \"Click on a poi and copy the gage id into the field below to view hydrographs and flow statistics.\",\n",
    "    style=\"bold yellow\",\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(poi_df.nhm_calib.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paste the poi_id in the field below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = widgets.Combobox(\n",
    "    # value='John',\n",
    "    placeholder=\"Enter Gage ID here\",\n",
    "    options=poi_df.poi_id.tolist(),\n",
    "    description=\"Plot Gage:\",\n",
    "    ensure_option=True,\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change(change):\n",
    "    global poi_id_sel, fig\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        poi_id_sel = v.value\n",
    "\n",
    "\n",
    "v.observe(on_change)\n",
    "\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poi_id_sel is None:\n",
    "    poi_id_sel = poi_df.poi_id.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poi_id_sel == None:\n",
    "    con.print(\n",
    "        \"Select a gage ID from the dropdown above or copy/paste from the map into the field.\"\n",
    "    )\n",
    "else:\n",
    "\n",
    "    # Single request\n",
    "    if len((obs_annual.sel(poi_id=poi_id_sel)).to_dataframe().dropna()) < 2:\n",
    "        con.print(\n",
    "            f\"The gage {poi_id_sel} has no observation data in the streamflow obs file.\"\n",
    "        )\n",
    "        pass\n",
    "    else:\n",
    "        df_sf_data_sel = (obs.sel(poi_id=poi_id_sel)).to_dataframe()\n",
    "\n",
    "        # Determine por\n",
    "        por_start = df_sf_data_sel[\"discharge\"].notna().idxmax()  # First Day\n",
    "        por_end = df_sf_data_sel[\"discharge\"].notna()[::-1].idxmax()  # Last Day\n",
    "\n",
    "        # Slice to por\n",
    "        df_sf_data_sel = (\n",
    "            obs.sel(poi_id=poi_id_sel, time=slice(por_start, por_end))\n",
    "        ).to_dataframe()\n",
    "        df_sf_data_sel.drop(columns=[\"poi_id\"], inplace=True)  # drop unwanted columns\n",
    "\n",
    "        obs_efc_sel = (\n",
    "            obs_efc.sel(poi_id=poi_id_sel, time=slice(por_start, por_end))\n",
    "        ).to_dataframe()\n",
    "        obs_efc_sel.drop(columns=[\"poi_id\"], inplace=True)  # drop unwanted columns\n",
    "        obs_with_efc_sel = df_sf_data_sel.merge(\n",
    "            obs_efc_sel, right_index=True, left_index=True, how=\"inner\"\n",
    "        )  # .dropna() #how='left' will slice ts with obs range\n",
    "\n",
    "        sim_flow = (\n",
    "            output_var.sel(npoi_gages=poi_id_sel, time=slice(por_start, por_end))\n",
    "        ).to_dataframe()\n",
    "        sim_flow.drop(columns=[\"npoi_gages\"], inplace=True)  # drop unwanted columns\n",
    "\n",
    "        # Create a dataframe for the NaN's that occur between the beginning and end of por\n",
    "        daily_efc_df = (\n",
    "            obs_with_efc_sel.merge(\n",
    "                sim_flow, right_index=True, left_index=True, how=\"inner\"\n",
    "            )\n",
    "        ).dropna()\n",
    "        daily_efc_plot_df = obs_with_efc_sel.merge(\n",
    "            sim_flow, right_index=True, left_index=True, how=\"inner\"\n",
    "        )\n",
    "        daily = df_sf_data_sel.merge(\n",
    "            sim_flow, right_index=True, left_index=True, how=\"inner\"\n",
    "        )\n",
    "        daily_na = daily[daily[\"discharge\"].isnull()]\n",
    "        daily_na[\"discharge\"] = 5.0\n",
    "\n",
    "        # drop the Nan's from the obs for memory/stats (may want to check back on this later)\n",
    "        daily_stat_df = (\n",
    "            df_sf_data_sel.merge(\n",
    "                sim_flow, right_index=True, left_index=True, how=\"inner\"\n",
    "            )\n",
    "        ).dropna()\n",
    "        daily_plot_df = df_sf_data_sel.merge(\n",
    "            sim_flow, right_index=True, left_index=True, how=\"inner\"\n",
    "        )  # .dropna()\n",
    "\n",
    "        # daily_stat_df_na = daily_stat_df[daily_stat_df['discharge'].isnull()]\n",
    "        # daily_stat_df = daily_stat_df.dropna()\n",
    "\n",
    "        # .dropna() #how='left' will slice ts with obs range\n",
    "        # daily_stat_df =streamflows_df.copy()#.dropna()\n",
    "        month_stat_df = daily_stat_df.resample(\"m\").mean().dropna()\n",
    "        month_plot_df = daily_plot_df.resample(\"m\").mean()  # .dropna()\n",
    "\n",
    "        water_year_stat_df = daily_stat_df.resample(\"A-SEP\").mean().dropna()\n",
    "        water_year_plot_df = daily_plot_df.resample(\"A-SEP\").mean()  # .dropna()\n",
    "\n",
    "        if len(daily_efc_df) <= 10000:\n",
    "            n = len(daily_efc_df)\n",
    "        else:\n",
    "            n = 10000  # Number of sampled days in records\n",
    "\n",
    "        ######################################################\n",
    "        # Make timeseries subplot figure\n",
    "        fig = plotly.subplots.make_subplots(\n",
    "            rows=3,\n",
    "            cols=2,\n",
    "            column_widths=[0.5, 0.5],  # row_heights=[0., 0.3, 0.3, 0.4],\n",
    "            shared_xaxes=\"columns\",\n",
    "            # shared_yaxes = 'columns',\n",
    "            start_cell=\"top-left\",\n",
    "            vertical_spacing=0.1,\n",
    "            horizontal_spacing=0.06,\n",
    "            # y_title=f\"Average daily streamflow, {getattr(model_output, output_var_sel).units}\",\n",
    "            y_title=f\"Average daily streamflow, {sf_units}\",\n",
    "            subplot_titles=[\n",
    "                \"Annual mean\",\n",
    "                f\"Flow Exceedence Curve, n = {n}\",\n",
    "                \"Monthly mean\",\n",
    "                \"Daily\",\n",
    "                \"Statistics\",\n",
    "            ],\n",
    "            specs=[\n",
    "                [{\"type\": \"scatter\"}, {\"type\": \"scatter\", \"rowspan\": 2}],\n",
    "                [{\"type\": \"scatter\"}, None],\n",
    "                [{\"type\": \"scatter\"}, {\"type\": \"table\"}],\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        station_name = station_name_df.loc[\n",
    "            station_name_df.index == poi_id_sel, \"poi_name\"\n",
    "        ].values[0]\n",
    "        date_range = f\"{daily_stat_df.index.month[0]}-{daily_stat_df.index.day[0]}-{daily_stat_df.index.year[0]} to {daily_plot_df.index.month[-1]}-{daily_plot_df.index.day[-1]}-{daily_plot_df.index.year[-1]} \"\n",
    "\n",
    "        fig.update_layout(\n",
    "            title_text=f\"NHM simulated streamflow at {poi_id_sel},<br>{station_name}, {date_range}\",  #\n",
    "            width=900,\n",
    "            height=700,\n",
    "            legend=dict(\n",
    "                orientation=\"h\", yanchor=\"bottom\", y=-0.15, xanchor=\"right\", x=0.7\n",
    "            ),\n",
    "            font=dict(family=\"Arial\", size=14, color=\"#7f7f7f\"),  # font color\n",
    "            paper_bgcolor=\"linen\",\n",
    "            plot_bgcolor=\"white\",\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title_automargin=True,\n",
    "            title_font_color=\"black\",\n",
    "            title_font_size=20,\n",
    "            title_x=0.5,\n",
    "            title_y=0.945,\n",
    "            title_xref=\"container\",\n",
    "            title_xanchor=\"center\",\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(range=[daily_plot_df.index[0], daily_plot_df.index[-1]])\n",
    "        # fig.update_xaxes(range = [(obs[\"time\"][0].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist()), (obs[\"time\"][-1].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist())])\n",
    "\n",
    "        # fig.update_layout(legend_grouptitlefont_color='black')\n",
    "        fig.update_layout(font_color=\"black\")\n",
    "\n",
    "        # fig.update_yaxes(title_text=f'{output_var_sel}, {getattr(model_output, output_var_sel).units}', title_font_color = 'black')\n",
    "        # fig.update_xaxes(title_text=\"Water years, from October 1 to September 31\", title_font_color = 'black')\n",
    "\n",
    "        fig.update_xaxes(ticks=\"inside\", tickwidth=2, tickcolor=\"black\", ticklen=10)\n",
    "        fig.update_yaxes(ticks=\"inside\", tickwidth=2, tickcolor=\"black\", ticklen=10)\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\"\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\"\n",
    "        )\n",
    "\n",
    "        fig.update_traces(hovertemplate=None)\n",
    "        fig.update_layout(hovermode=\"x unified\")  # \"x unified\"\n",
    "        fig.update_layout(\n",
    "            hoverlabel=dict(\n",
    "                bgcolor=\"linen\",\n",
    "                font_size=13,\n",
    "                font_family=\"Rockwell\",\n",
    "            )\n",
    "        )\n",
    "        # Useful xarray calls\n",
    "        # f'{(obs[\"time\"][0].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist())} to {(obs[\"time\"][-1].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist())} '\n",
    "        # x_values_annual = (output_var_annual[\"time\"].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist())\n",
    "        # sim_values_annual = (output_var_annual.sel(npoi_gages = poi_id_sel).values.tolist())\n",
    "        # obs_values = (obs_annual.sel(poi_id = poi_id_sel).values.tolist())\n",
    "\n",
    "        ######################################################\n",
    "        # Create annual subplot\n",
    "        annual_plots = [\n",
    "            go.Scatter(\n",
    "                x=water_year_plot_df.index,\n",
    "                y=water_year_plot_df.discharge,\n",
    "                mode=\"lines\",\n",
    "                name=\"Observed flow, annual\",\n",
    "                showlegend=False,\n",
    "                # marker=dict(color='brown'),\n",
    "                # xaxis =\n",
    "                line=dict(\n",
    "                    color=\"deepskyblue\",\n",
    "                    width=4,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=water_year_plot_df.index,\n",
    "                y=water_year_plot_df.seg_outflow,\n",
    "                mode=\"lines\",\n",
    "                name=\"Simulated flow, annual\",\n",
    "                showlegend=False,\n",
    "                # marker=dict(color='brown'),\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "        annual_fig = go.Figure(data=annual_plots)\n",
    "\n",
    "        ######################################################\n",
    "        # Create monthly subplot\n",
    "        monthly_plots = [\n",
    "            go.Scatter(\n",
    "                x=month_plot_df.index,\n",
    "                y=month_plot_df.discharge,\n",
    "                mode=\"lines\",\n",
    "                name=\"Observed flow, monthly\",\n",
    "                showlegend=False,\n",
    "                # marker=dict(color='brown'),\n",
    "                # xaxis =\n",
    "                line=dict(\n",
    "                    color=\"deepskyblue\",\n",
    "                    width=4,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=month_plot_df.index,\n",
    "                y=month_plot_df.seg_outflow,\n",
    "                mode=\"lines\",\n",
    "                name=\"Simulated flow, monthly\",\n",
    "                showlegend=False,\n",
    "                # marker=dict(color='brown'),\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "        monthly_fig = go.Figure(data=monthly_plots)\n",
    "\n",
    "        ######################################################\n",
    "        # Create daily subplot\n",
    "        # Make a line set for na values to show no data in the plot.\n",
    "\n",
    "        # daily_efc_exlow_df = daily_efc_df.loc[daily_efc_df['efc'].isin([5])]\n",
    "        daily_efc_low_plot_df = daily_efc_plot_df.copy()\n",
    "        daily_efc_low_plot_df.loc[daily_efc_low_plot_df[\"efc\"] <= 3, \"discharge\"] = (\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        daily_efc_high_plot_df = daily_efc_plot_df.copy()\n",
    "        daily_efc_high_plot_df.loc[daily_efc_high_plot_df[\"efc\"] >= 4, \"discharge\"] = (\n",
    "            np.nan\n",
    "        )\n",
    "\n",
    "        daily_plots = [\n",
    "            go.Scatter(\n",
    "                x=daily_efc_high_plot_df.index,  # (output_var[\"time\"].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist()),\n",
    "                y=daily_efc_high_plot_df.discharge,  # (obs.sel(poi_id = poi_id_sel).values.tolist()),\n",
    "                mode=\"lines\",\n",
    "                name=\"Observed flow\",\n",
    "                showlegend=True,\n",
    "                connectgaps=False,\n",
    "                # marker=dict(color='deepskyblue', size = 5),\n",
    "                # xaxis =\n",
    "                line=dict(\n",
    "                    color=\"deepskyblue\",\n",
    "                    width=4,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=daily_efc_low_plot_df.index,  # (output_var[\"time\"].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist()),\n",
    "                y=daily_efc_low_plot_df.discharge,  # (obs.sel(poi_id = poi_id_sel).values.tolist()),\n",
    "                mode=\"lines\",\n",
    "                name=\"Observed flow, (Low)\",\n",
    "                showlegend=True,\n",
    "                connectgaps=False,\n",
    "                # marker=dict(color='deepskyblue', size = 5),\n",
    "                # xaxis =\n",
    "                line=dict(\n",
    "                    color=\"red\",\n",
    "                    width=4,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=daily_plot_df.index,  # (output_var[\"time\"].dt.datetime.strftime(\"%Y-%m-%d\").values.tolist()),\n",
    "                y=daily_plot_df.seg_outflow,  # (output_var.sel(npoi_gages = poi_id_sel).values.tolist()),\n",
    "                mode=\"lines\",\n",
    "                name=\"Simulated flow, daily\",\n",
    "                showlegend=False,\n",
    "                # marker=dict(color='black', size = 3),\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "        #######################################################\n",
    "        # EFC classifications\n",
    "        # 1 = Large floods\n",
    "        # 2 = Small floods\n",
    "        # 3 = High flow pulses\n",
    "        # 4 = Low flows\n",
    "        # 5 = Extreme low flows\n",
    "\n",
    "        daily_df = stats_table(daily_stat_df)\n",
    "        daily_df[\"time\"] = \"daily\"\n",
    "        monthly_df = stats_table(month_stat_df)\n",
    "        monthly_df[\"time\"] = \"monthly\"\n",
    "        annual_df = stats_table(water_year_stat_df)\n",
    "        annual_df[\"time\"] = \"annual\"\n",
    "\n",
    "        # daily_efc_exlow_df = daily_efc_df.loc[daily_efc_df['efc'].isin([5])]\n",
    "        daily_efc_low_df = daily_efc_df.loc[daily_efc_df[\"efc\"].isin([4, 5])]\n",
    "        daily_efc_high_df = daily_efc_df.loc[daily_efc_df[\"efc\"].isin([1, 2, 3])]\n",
    "\n",
    "        # daily_exlow_tab_df = stats_table(daily_efc_exlow_df)\n",
    "        # daily_exlow_tab_df['time'] = 'exlow'\n",
    "        # daily_exlow_tab_df[['NSE','KGE']] = np.nan\n",
    "\n",
    "        daily_low_tab_df = stats_table(daily_efc_low_df)\n",
    "        daily_low_tab_df[\"time\"] = \"low\"\n",
    "        daily_low_tab_df[[\"NSE\", \"KGE\"]] = np.nan\n",
    "\n",
    "        daily_high_tab_df = stats_table(daily_efc_high_df)\n",
    "        daily_high_tab_df[\"time\"] = \"high\"\n",
    "        daily_high_tab_df[[\"NSE\", \"KGE\"]] = np.nan\n",
    "\n",
    "        all_df = pd.concat(\n",
    "            [\n",
    "                daily_df,\n",
    "                daily_low_tab_df,\n",
    "                daily_high_tab_df,\n",
    "                monthly_df,\n",
    "                annual_df,\n",
    "            ]\n",
    "        )\n",
    "        all_df.set_index(\"time\", inplace=True)\n",
    "        stats_table_df = all_df.T\n",
    "        # stats_table_df\n",
    "\n",
    "        stats_table_obj = go.Figure(\n",
    "            data=[\n",
    "                go.Table(\n",
    "                    header=dict(\n",
    "                        values=[\n",
    "                            \"Statistic\",\n",
    "                            \"Daily\",\n",
    "                            \"Low\",\n",
    "                            \"High\",\n",
    "                            \"Monthly\",\n",
    "                            \"Annual\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    cells=dict(\n",
    "                        values=[\n",
    "                            stats_table_df.index,\n",
    "                            stats_table_df.daily,\n",
    "                            stats_table_df.low,\n",
    "                            stats_table_df.high,\n",
    "                            stats_table_df.monthly,\n",
    "                            stats_table_df.annual,\n",
    "                        ]\n",
    "                    ),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        #######################################################\n",
    "\n",
    "        obs_data = daily_efc_df.discharge.sample(\n",
    "            n=n, replace=False, random_state=3  # frac=0.25,\n",
    "        )\n",
    "        sim_data = daily_efc_df.seg_outflow.sample(\n",
    "            n=n, replace=False, random_state=3  # frac=0.25,\n",
    "        )\n",
    "\n",
    "        obs_sort = np.sort(obs_data)[::-1]\n",
    "        sim_sort = np.sort(sim_data)[::-1]\n",
    "        obs_color_sort = daily_efc_df.sort_values(\"discharge\")[\n",
    "            ::-1\n",
    "        ]  # Makes the color value sort in same order for use in plot.\n",
    "\n",
    "        obs_exceedence = np.arange(1.0, len(obs_sort) + 1) / len(obs_sort)\n",
    "        sim_exceedence = np.arange(1.0, len(sim_sort) + 1) / len(sim_sort)\n",
    "\n",
    "        efc_colors = {\n",
    "            1: \"rgba(0, 191, 255, 0.5)\",  # Large Floods\n",
    "            0: \"white\",\n",
    "            2: \"rgba(0, 191, 255, 0.5)\",  # Small Floods\n",
    "            3: \"rgba(0, 191, 255, 0.5)\",  # High Flow Pulse\n",
    "            4: \"rgba(255, 0, 0, 0.5)\",  # Low\n",
    "            5: \"rgba(255, 0, 0, 0.5)\",  # Extreemly Low\n",
    "            np.nan: \"yellow\",\n",
    "        }  # missing\n",
    "        # or ...color_discrete_sequence = plotly.colors.sequential.Viridis\n",
    "\n",
    "        custom_marker_color = obs_color_sort[\"efc\"].map(efc_colors)\n",
    "\n",
    "        exceed_plot = [\n",
    "            go.Scatter(\n",
    "                x=obs_exceedence,\n",
    "                y=obs_sort,\n",
    "                mode=\"markers\",\n",
    "                name=\"Observed flow\",\n",
    "                marker=dict(color=custom_marker_color, size=3),\n",
    "                showlegend=False,\n",
    "                # line = dict(color='deepskyblue',\n",
    "                #    width=3,\n",
    "                # dash='dot'\n",
    "                # )\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=sim_exceedence,\n",
    "                y=sim_sort,\n",
    "                mode=\"lines\",\n",
    "                name=\"NHM simulated flow\",\n",
    "                showlegend=False,\n",
    "                # marker=dict(#color='brown',\n",
    "                #            size=1),\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    # dash='dot'\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        exceed_fig = go.Figure(data=exceed_plot)\n",
    "\n",
    "        # fig.update_yaxes(title_text=f'Streamflow, {getattr(model_output, \"seg_outflow\").units}', title_font_color = 'black', row=1, col=3)\n",
    "        # fig.update_xaxes(title_text=\"Exceedence, probability\", title_font_color = 'black', row=1, col=3)\n",
    "\n",
    "        fig.update_yaxes(type=\"log\", col=2)\n",
    "\n",
    "        tickvals = [\n",
    "            0,\n",
    "            1,\n",
    "            2,\n",
    "            5,\n",
    "            10,\n",
    "            20,\n",
    "            50,\n",
    "            100,\n",
    "            200,\n",
    "            500,\n",
    "            1000,\n",
    "            2000,\n",
    "            5000,\n",
    "            10000,\n",
    "            20000,\n",
    "            50000,\n",
    "            100000,\n",
    "            200000,\n",
    "            500000,\n",
    "            1000000,\n",
    "        ]\n",
    "\n",
    "        tickvals_exceed = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            tickvals=tickvals_exceed,\n",
    "            ticks=\"inside\",\n",
    "            tickwidth=2,\n",
    "            tickcolor=\"black\",\n",
    "            showticklabels=True,\n",
    "            ticklen=10,\n",
    "            col=2,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            tickvals=tickvals,\n",
    "            ticks=\"inside\",\n",
    "            tickwidth=2,\n",
    "            tickcolor=\"black\",\n",
    "            ticklen=10,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor=\"black\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "            range=[-0.1, 1.1],\n",
    "            col=2,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            showline=True, linewidth=2, linecolor=\"black\", gridcolor=\"lightgrey\", col=2\n",
    "        )\n",
    "\n",
    "        #######################################################\n",
    "        # Add plots and stats tables to figure\n",
    "        daily_fig = go.Figure(data=daily_plots)\n",
    "\n",
    "        for t in annual_fig.data:\n",
    "            fig.append_trace(t, row=1, col=1)\n",
    "        for t in monthly_fig.data:\n",
    "            fig.append_trace(t, row=2, col=1)\n",
    "        for t in daily_fig.data:\n",
    "            fig.append_trace(t, row=3, col=1)\n",
    "        for t in exceed_fig.data:\n",
    "            fig.append_trace(t, row=1, col=2)\n",
    "        for t in stats_table_obj.data:\n",
    "            fig.append_trace(t, row=3, col=2)\n",
    "\n",
    "        # # Creating the html code for the plotly plot\n",
    "        # text_div = plotly.offline.plot(fig, include_plotlyjs=False, output_type=\"div\")\n",
    "\n",
    "        # # Saving the plot as txt file with the html code\n",
    "        # # idx = 1\n",
    "        # with open(Folium_maps_dir / f\"streamflow_{poi_id_sel}.txt\", \"w\") as f:\n",
    "        #     f.write(text_div)\n",
    "        fig.write_html(Folium_maps_dir / f\"streamflow_{poi_id_sel}.html\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add D scores into here (sydney and Tim); maybe use the differenct components of the EFC rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
